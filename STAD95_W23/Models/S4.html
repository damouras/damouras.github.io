

<!DOCTYPE html>


<html >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>&lt;no title&gt; &#8212; Electricity Demand Forecasting</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=12da95d707ffb74b382d" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=12da95d707ffb74b382d" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=12da95d707ffb74b382d" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=12da95d707ffb74b382d" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=12da95d707ffb74b382d" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=12da95d707ffb74b382d" />

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'Models/S4';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="None"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../data.html">Data Description</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../EDApy.html">EDA</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../methods.html">Methodology</a></li>
<li class="toctree-l1"><a class="reference internal" href="../results.html">Results</a></li>
<li class="toctree-l1"><a class="reference internal" href="../discussion.html">Conclusion</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/damouras/STAD95_W23" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/damouras/STAD95_W23/issues/new?title=Issue%20on%20page%20%2FModels/S4.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/Models/S4.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1><no title></h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="simple visible nav section-nav flex-column">
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <p>#Import stuffs</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>!pip install pytorch-lightning
!pip install einops
!pip install pykeops
!pip install opt-einsum
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting pytorch-lightning
  Downloading pytorch_lightning-2.0.0-py3-none-any.whl (715 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ <span class=" -Color -Color-Green">715.6/715.6 KB</span> <span class=" -Color -Color-Red">7.8 MB/s</span> eta <span class=" -Color -Color-Cyan">0:00:00</span>
?25hRequirement already satisfied: PyYAML&gt;=5.4 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (6.0)
Requirement already satisfied: numpy&gt;=1.17.2 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (1.22.4)
Requirement already satisfied: fsspec[http]&gt;2021.06.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (2023.3.0)
Requirement already satisfied: typing-extensions&gt;=4.0.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (4.5.0)
Collecting lightning-utilities&gt;=0.7.0
  Downloading lightning_utilities-0.8.0-py3-none-any.whl (20 kB)
Requirement already satisfied: tqdm&gt;=4.57.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (4.65.0)
Requirement already satisfied: torch&gt;=1.11.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (1.13.1+cu116)
Requirement already satisfied: packaging&gt;=17.1 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (23.0)
Collecting torchmetrics&gt;=0.7.0
  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ <span class=" -Color -Color-Green">519.2/519.2 KB</span> <span class=" -Color -Color-Red">19.0 MB/s</span> eta <span class=" -Color -Color-Cyan">0:00:00</span>
?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from fsspec[http]&gt;2021.06.0-&gt;pytorch-lightning) (2.27.1)
Collecting aiohttp!=4.0.0a0,!=4.0.0a1
  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ <span class=" -Color -Color-Green">1.0/1.0 MB</span> <span class=" -Color -Color-Red">16.8 MB/s</span> eta <span class=" -Color -Color-Cyan">0:00:00</span>
?25hCollecting aiosignal&gt;=1.1.2
  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)
Collecting async-timeout&lt;5.0,&gt;=4.0.0a3
  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)
Collecting multidict&lt;7.0,&gt;=4.5
  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ <span class=" -Color -Color-Green">114.2/114.2 KB</span> <span class=" -Color -Color-Red">10.0 MB/s</span> eta <span class=" -Color -Color-Cyan">0:00:00</span>
?25hRequirement already satisfied: charset-normalizer&lt;4.0,&gt;=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-&gt;fsspec[http]&gt;2021.06.0-&gt;pytorch-lightning) (2.0.12)
Requirement already satisfied: attrs&gt;=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-&gt;fsspec[http]&gt;2021.06.0-&gt;pytorch-lightning) (22.2.0)
Collecting yarl&lt;2.0,&gt;=1.0
  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ <span class=" -Color -Color-Green">264.6/264.6 KB</span> <span class=" -Color -Color-Red">22.7 MB/s</span> eta <span class=" -Color -Color-Cyan">0:00:00</span>
?25hCollecting frozenlist&gt;=1.1.1
  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ <span class=" -Color -Color-Green">158.8/158.8 KB</span> <span class=" -Color -Color-Red">14.5 MB/s</span> eta <span class=" -Color -Color-Cyan">0:00:00</span>
?25hRequirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.9/dist-packages (from requests-&gt;fsspec[http]&gt;2021.06.0-&gt;pytorch-lightning) (3.4)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests-&gt;fsspec[http]&gt;2021.06.0-&gt;pytorch-lightning) (2022.12.7)
Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests-&gt;fsspec[http]&gt;2021.06.0-&gt;pytorch-lightning) (1.26.15)
Installing collected packages: multidict, lightning-utilities, frozenlist, async-timeout, yarl, torchmetrics, aiosignal, aiohttp, pytorch-lightning
Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 lightning-utilities-0.8.0 multidict-6.0.4 pytorch-lightning-2.0.0 torchmetrics-0.11.4 yarl-1.8.2
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting einops
  Downloading einops-0.6.0-py3-none-any.whl (41 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ <span class=" -Color -Color-Green">41.6/41.6 KB</span> <span class=" -Color -Color-Red">2.3 MB/s</span> eta <span class=" -Color -Color-Cyan">0:00:00</span>
?25hInstalling collected packages: einops
Successfully installed einops-0.6.0
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting pykeops
  Downloading pykeops-2.1.1.tar.gz (87 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ <span class=" -Color -Color-Green">87.4/87.4 KB</span> <span class=" -Color -Color-Red">3.1 MB/s</span> eta <span class=" -Color -Color-Cyan">0:00:00</span>
?25h  Preparing metadata (setup.py) ... ?25l?25hdone
Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from pykeops) (1.22.4)
Collecting pybind11
  Downloading pybind11-2.10.4-py3-none-any.whl (222 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ <span class=" -Color -Color-Green">222.3/222.3 KB</span> <span class=" -Color -Color-Red">9.6 MB/s</span> eta <span class=" -Color -Color-Cyan">0:00:00</span>
?25hCollecting keopscore==2.1.1
  Downloading keopscore-2.1.1.tar.gz (84 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ <span class=" -Color -Color-Green">84.6/84.6 KB</span> <span class=" -Color -Color-Red">8.1 MB/s</span> eta <span class=" -Color -Color-Cyan">0:00:00</span>
?25h  Preparing metadata (setup.py) ... ?25l?25hdone
Building wheels for collected packages: pykeops, keopscore
  Building wheel for pykeops (setup.py) ... ?25l?25hdone
  Created wheel for pykeops: filename=pykeops-2.1.1-py3-none-any.whl size=112293 sha256=11233af18cd5f1d13af1d2fc6cef627bc38b688f8f2aa0188d87f808e91b8ae8
  Stored in directory: /root/.cache/pip/wheels/22/ac/b4/3ced6d88473155a4fc54174add9c4438f2d412864b5a5b6664
  Building wheel for keopscore (setup.py) ... ?25l?25hdone
  Created wheel for keopscore: filename=keopscore-2.1.1-py3-none-any.whl size=148011 sha256=5dc65988d067d3e3f000e47a3f73e5a8d6ee7c47649e8af04fcb023641bdc78c
  Stored in directory: /root/.cache/pip/wheels/90/73/4e/4b76402bc0c6343c69d0a35539d3c551f65fcd82eec5aad8b6
Successfully built pykeops keopscore
Installing collected packages: pybind11, keopscore, pykeops
Successfully installed keopscore-2.1.1 pybind11-2.10.4 pykeops-2.1.1
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: opt-einsum in /usr/local/lib/python3.9/dist-packages (3.3.0)
Requirement already satisfied: numpy&gt;=1.7 in /usr/local/lib/python3.9/dist-packages (from opt-einsum) (1.22.4)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#import required libraries</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span> <span class="k">as</span> <span class="n">dt</span>

<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <span class="n">BaseEstimator</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <span class="n">TransformerMixin</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">TensorDataset</span><span class="p">,</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">Module</span><span class="p">,</span> <span class="n">Parameter</span>

<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">special</span> <span class="k">as</span> <span class="n">ss</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.utilities</span> <span class="kn">import</span> <span class="n">rank_zero_only</span>
<span class="kn">from</span> <span class="nn">einops</span> <span class="kn">import</span> <span class="n">rearrange</span><span class="p">,</span> <span class="n">repeat</span>
<span class="kn">import</span> <span class="nn">opt_einsum</span> <span class="k">as</span> <span class="nn">oe</span>
<span class="kn">import</span> <span class="nn">datetime</span>

<span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">67686970</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">67686970</span><span class="p">)</span>

<span class="n">contract</span> <span class="o">=</span> <span class="n">oe</span><span class="o">.</span><span class="n">contract</span>
<span class="n">contract_expression</span> <span class="o">=</span> <span class="n">oe</span><span class="o">.</span><span class="n">contract_expression</span>

<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">read_data</span><span class="p">():</span>
  <span class="c1"># Load CSV into dataframe and format</span>
  <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;final_daily.csv&#39;</span><span class="p">)</span>
  <span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">])</span>
  <span class="n">df</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span><span class="o">&lt;</span><span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="p">(</span><span class="mi">2023</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)]</span>

  <span class="n">variable</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">,</span> <span class="s1">&#39;demand&#39;</span><span class="p">,</span> <span class="s1">&#39;avg_temp&#39;</span><span class="p">]</span>

  <span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
  <span class="n">df</span><span class="p">[</span><span class="n">variable</span><span class="p">]</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">variable</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">variable</span><span class="p">)))</span>

  <span class="n">VAL_PERC</span> <span class="o">=</span> <span class="mf">0.30</span>

  <span class="n">n_train</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">[:</span><span class="o">-</span><span class="mi">365</span><span class="p">])</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">VAL_PERC</span><span class="p">))</span>

  <span class="n">dataframe_train</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">variable</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="n">n_train</span><span class="p">]</span>
  <span class="n">train_df</span> <span class="o">=</span> <span class="n">dataframe_train</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">variable</span><span class="p">))</span>

  <span class="n">dataframe_val</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">variable</span><span class="p">][</span><span class="n">n_train</span><span class="p">:</span><span class="o">-</span><span class="mi">365</span><span class="p">]</span>
  <span class="n">val_df</span> <span class="o">=</span> <span class="n">dataframe_val</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">variable</span><span class="p">))</span>

  <span class="n">dataframe_test</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">variable</span><span class="p">][</span><span class="o">-</span><span class="mi">365</span><span class="p">:]</span>
  <span class="n">test_df</span> <span class="o">=</span> <span class="n">dataframe_test</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">variable</span><span class="p">))</span>

  <span class="n">dataframe_dataset</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">variable</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
  <span class="n">dataset</span><span class="o">=</span> <span class="n">dataframe_dataset</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">variable</span><span class="p">))</span>

  <span class="k">return</span> <span class="n">df</span><span class="p">,</span> <span class="n">train_df</span><span class="p">,</span> <span class="n">val_df</span><span class="p">,</span> <span class="n">test_df</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">scaler</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">to_sequences</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">seq_size</span><span class="p">):</span> <span class="c1"># seq_size is Number of time steps to look back </span>
                                       <span class="c1">#Larger sequences (look further back) may improve forecasting.</span>
    <span class="n">x</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">y</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span><span class="o">-</span><span class="n">seq_size</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">window</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="n">i</span><span class="p">:(</span><span class="n">i</span><span class="o">+</span><span class="n">seq_size</span><span class="p">),</span> <span class="p">:]</span>
        <span class="n">x</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">window</span><span class="p">)</span>
        <span class="n">y</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="n">seq_size</span><span class="p">,</span> <span class="p">:])</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">EarlyStopping</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Early stops the training if validation loss doesn&#39;t improve after a given patience.&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            patience (int): How long to wait after last time validation loss improved.</span>
<span class="sd">                            Default: 7</span>
<span class="sd">            verbose (bool): If True, prints a message for each validation loss improvement. </span>
<span class="sd">                            Default: False</span>
<span class="sd">            delta (float): Minimum change in the monitored quantity to qualify as an improvement.</span>
<span class="sd">                            Default: 0</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">patience</span> <span class="o">=</span> <span class="n">patience</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best_score</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">early_stop</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_loss_min</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">Inf</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">delta</span> <span class="o">=</span> <span class="n">delta</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">):</span>

        <span class="n">score</span> <span class="o">=</span> <span class="o">-</span><span class="n">val_loss</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_score</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best_score</span> <span class="o">=</span> <span class="n">score</span>
        <span class="k">elif</span> <span class="n">score</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_score</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">delta</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;EarlyStopping counter: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">counter</span><span class="si">}</span><span class="s1"> out of </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">patience</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">patience</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">early_stop</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best_score</span> <span class="o">=</span> <span class="n">score</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
</pre></div>
</div>
</div>
</div>
<p>#S4 setups</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pykeops</span>
<span class="kn">from</span> <span class="nn">pykeops.torch</span> <span class="kn">import</span> <span class="n">Genred</span>
<span class="n">has_pykeops</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">def</span> <span class="nf">cauchy_conj</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Pykeops version &quot;&quot;&quot;</span>
    <span class="n">expr_num</span> <span class="o">=</span> <span class="s1">&#39;z * ComplexReal(v) - Real2Complex(Sum(v * w))&#39;</span>
    <span class="n">expr_denom</span> <span class="o">=</span> <span class="s1">&#39;ComplexMult(z-w, z-Conj(w))&#39;</span>

    <span class="n">cauchy_mult</span> <span class="o">=</span> <span class="n">Genred</span><span class="p">(</span>
        <span class="sa">f</span><span class="s1">&#39;ComplexDivide(</span><span class="si">{</span><span class="n">expr_num</span><span class="si">}</span><span class="s1">, </span><span class="si">{</span><span class="n">expr_denom</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">,</span>
        <span class="c1"># expr_num,</span>
        <span class="c1"># expr_denom,</span>
        <span class="p">[</span>
            <span class="s1">&#39;v = Vj(2)&#39;</span><span class="p">,</span>
            <span class="s1">&#39;z = Vi(2)&#39;</span><span class="p">,</span>
            <span class="s1">&#39;w = Vj(2)&#39;</span><span class="p">,</span>
        <span class="p">],</span>
        <span class="n">reduction_op</span><span class="o">=</span><span class="s1">&#39;Sum&#39;</span><span class="p">,</span>
        <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">v</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">_broadcast_dims</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">_c2r</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">_c2r</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">_c2r</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>

    <span class="n">r</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">cauchy_mult</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">_r2c</span><span class="p">(</span><span class="n">r</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">_broadcast_dims</span><span class="p">(</span><span class="o">*</span><span class="n">tensors</span><span class="p">):</span>
    <span class="n">max_dim</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">tensors</span><span class="p">])</span>
    <span class="n">tensors</span> <span class="o">=</span> <span class="p">[</span><span class="n">tensor</span><span class="o">.</span><span class="n">view</span><span class="p">((</span><span class="mi">1</span><span class="p">,)</span><span class="o">*</span><span class="p">(</span><span class="n">max_dim</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span><span class="o">+</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">tensors</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">tensors</span>

<span class="n">_c2r</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">view_as_real</span>
<span class="n">_r2c</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">view_as_complex</span>
<span class="n">_conj</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">conj</span><span class="p">()],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="k">if</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)[:</span><span class="mi">2</span><span class="p">]))</span> <span class="o">&gt;=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">):</span>
    <span class="n">_resolve_conj</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">conj</span><span class="p">()</span><span class="o">.</span><span class="n">resolve_conj</span><span class="p">()</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">_resolve_conj</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">conj</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">TransposedLinear</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Linear module on the second-to-last dimension &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_input</span><span class="p">,</span> <span class="n">d_output</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">d_output</span><span class="p">,</span> <span class="n">d_input</span><span class="p">))</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">5</span><span class="p">))</span> <span class="c1"># nn.Linear default init</span>
        <span class="c1"># nn.init.kaiming_uniform_(self.weight, nonlinearity=&#39;linear&#39;) # should be equivalent</span>

        <span class="k">if</span> <span class="n">bias</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">d_output</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
            <span class="n">bound</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">d_input</span><span class="p">)</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="o">-</span><span class="n">bound</span><span class="p">,</span> <span class="n">bound</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">contract</span><span class="p">(</span><span class="s1">&#39;... u l, v u -&gt; ... v l&#39;</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">LinearActivation</span><span class="p">(</span>
        <span class="n">d_input</span><span class="p">,</span> <span class="n">d_output</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">zero_bias_init</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">transposed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">weight_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Returns a linear nn.Module with control over axes order, initialization, and activation &quot;&quot;&quot;</span>

    <span class="c1"># Construct core module</span>
    <span class="n">linear_cls</span> <span class="o">=</span> <span class="n">TransposedLinear</span> <span class="k">if</span> <span class="n">transposed</span> <span class="k">else</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span>
    <span class="c1">#if activation == &#39;glu&#39;: d_output *= 2</span>
    <span class="n">linear</span> <span class="o">=</span> <span class="n">linear_cls</span><span class="p">(</span><span class="n">d_input</span><span class="p">,</span> <span class="n">d_output</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">)</span>

    <span class="c1"># Initialize weight</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_uniform_</span><span class="p">(</span><span class="n">linear</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>

    <span class="c1"># Initialize bias</span>
    <span class="k">if</span> <span class="n">bias</span> <span class="ow">and</span> <span class="n">zero_bias_init</span><span class="p">:</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">zeros_</span><span class="p">(</span><span class="n">linear</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>

    <span class="c1"># Weight norm</span>
    <span class="k">if</span> <span class="n">weight_norm</span><span class="p">:</span>
        <span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">weight_norm</span><span class="p">(</span><span class="n">linear</span><span class="p">)</span>

    <span class="n">activation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
    <span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">linear</span><span class="p">,</span> <span class="n">activation</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">linear</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot; Misc functional utilities &quot;&quot;&quot;</span>

<span class="k">def</span> <span class="nf">krylov</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_power</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the Krylov matrix (b, Ab, A^2b, ...) using the squaring trick.</span>
<span class="sd">    If return_power=True, return A^{L-1} as well</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO There is an edge case if L=1 where output doesn&#39;t get broadcasted, which might be an issue if caller is expecting broadcasting semantics... can deal with it if it arises</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">b</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># (..., N, 1)</span>
    <span class="n">A_</span> <span class="o">=</span> <span class="n">A</span>

    <span class="n">AL</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">return_power</span><span class="p">:</span>
        <span class="n">AL</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">A</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">A</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">_L</span> <span class="o">=</span> <span class="n">L</span><span class="o">-</span><span class="mi">1</span>

    <span class="n">done</span> <span class="o">=</span> <span class="n">L</span> <span class="o">==</span> <span class="mi">1</span>
    <span class="c1"># loop invariant: _L represents how many indices left to compute</span>
    <span class="k">while</span> <span class="ow">not</span> <span class="n">done</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">return_power</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">_L</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span> <span class="n">AL</span> <span class="o">=</span> <span class="n">A_</span> <span class="o">@</span> <span class="n">AL</span>
            <span class="n">_L</span> <span class="o">//=</span> <span class="mi">2</span>

        <span class="c1"># Save memory on last iteration</span>
        <span class="n">l</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">L</span> <span class="o">-</span> <span class="n">l</span> <span class="o">&lt;=</span> <span class="n">l</span><span class="p">:</span>
            <span class="n">done</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">_x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="n">L</span><span class="o">-</span><span class="n">l</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span> <span class="n">_x</span> <span class="o">=</span> <span class="n">x</span>

        <span class="n">_x</span> <span class="o">=</span> <span class="n">A_</span> <span class="o">@</span> <span class="n">_x</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">_x</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># there might be a more efficient way of ordering axes</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">done</span><span class="p">:</span> <span class="n">A_</span> <span class="o">=</span> <span class="n">A_</span> <span class="o">@</span> <span class="n">A_</span>

    <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">L</span>

    <span class="k">if</span> <span class="n">c</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;...nl, ...n -&gt; ...l&#39;</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span> <span class="c1"># WOW!!</span>
    <span class="k">if</span> <span class="n">return_power</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">AL</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">power</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">v</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Compute A^L and the scan sum_i A^i v_i</span>
<span class="sd">    A: (..., N, N)</span>
<span class="sd">    v: (..., N, L)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">I</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">A</span><span class="p">)</span> <span class="c1"># , dtype=A.dtype, device=A.device)</span>

    <span class="n">powers</span> <span class="o">=</span> <span class="p">[</span><span class="n">A</span><span class="p">]</span>
    <span class="n">l</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">L</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span> <span class="n">I</span> <span class="o">=</span> <span class="n">powers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">@</span> <span class="n">I</span>
        <span class="n">L</span> <span class="o">//=</span> <span class="mi">2</span>
        <span class="k">if</span> <span class="n">L</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="k">break</span>
        <span class="n">l</span> <span class="o">*=</span> <span class="mi">2</span>
        <span class="n">powers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">powers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">@</span> <span class="n">powers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

    <span class="k">if</span> <span class="n">v</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="k">return</span> <span class="n">I</span>

    <span class="c1"># Invariants:</span>
    <span class="c1"># powers[-1] := A^l</span>
    <span class="c1"># l := largest po2 at most L</span>

    <span class="c1"># Note that an alternative divide and conquer to compute the reduction is possible and can be embedded into the above loop without caching intermediate powers of A</span>
    <span class="c1"># We do this reverse divide-and-conquer for efficiency reasons:</span>
    <span class="c1"># 1) it involves fewer padding steps for non-po2 L</span>
    <span class="c1"># 2) it involves more contiguous arrays</span>

    <span class="c1"># Take care of edge case for non-po2 arrays</span>
    <span class="c1"># Note that this initial step is a no-op for the case of power of 2 (l == L)</span>
    <span class="n">k</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">l</span>
    <span class="n">v_</span> <span class="o">=</span> <span class="n">powers</span><span class="o">.</span><span class="n">pop</span><span class="p">()</span> <span class="o">@</span> <span class="n">v</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">l</span><span class="p">:]</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">v</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="n">l</span><span class="p">]</span>
    <span class="n">v</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="n">k</span><span class="p">]</span> <span class="o">+</span> <span class="n">v_</span>

    <span class="c1"># Handle reduction for power of 2</span>
    <span class="k">while</span> <span class="n">v</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="s1">&#39;... (z l) -&gt; ... z l&#39;</span><span class="p">,</span> <span class="n">z</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">v</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">+</span> <span class="n">powers</span><span class="o">.</span><span class="n">pop</span><span class="p">()</span> <span class="o">@</span> <span class="n">v</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
    <span class="k">return</span> <span class="n">I</span><span class="p">,</span> <span class="n">v</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot; HiPPO utilities &quot;&quot;&quot;</span>

<span class="k">def</span> <span class="nf">embed_c2r</span><span class="p">(</span><span class="n">A</span><span class="p">):</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="s1">&#39;... m n -&gt; ... m () n ()&#39;</span><span class="p">)</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span> <span class="o">+</span> \
        <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">)))</span>
    <span class="k">return</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="s1">&#39;m x n y -&gt; (m x) (n y)&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">transition</span><span class="p">(</span><span class="n">measure</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="o">**</span><span class="n">measure_args</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; A, B transition matrices for different measures</span>
<span class="sd">    measure: the type of measure</span>
<span class="sd">      legt - Legendre (translated)</span>
<span class="sd">      legs - Legendre (scaled)</span>
<span class="sd">      glagt - generalized Laguerre (translated)</span>
<span class="sd">      lagt, tlagt - previous versions of (tilted) Laguerre with slightly different normalization</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Laguerre (translated)</span>
    <span class="k">if</span> <span class="n">measure</span> <span class="o">==</span> <span class="s1">&#39;lagt&#39;</span><span class="p">:</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">measure_args</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;beta&#39;</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
        <span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">N</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">tril</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">N</span><span class="p">)))</span>
        <span class="n">B</span> <span class="o">=</span> <span class="n">b</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="c1"># Generalized Laguerre</span>
    <span class="c1"># alpha 0, beta small is most stable (limits to the &#39;lagt&#39; measure)</span>
    <span class="c1"># alpha 0, beta 1 has transition matrix A = [lower triangular 1]</span>
    <span class="k">elif</span> <span class="n">measure</span> <span class="o">==</span> <span class="s1">&#39;glagt&#39;</span><span class="p">:</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="n">measure_args</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;alpha&#39;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
        <span class="n">beta</span> <span class="o">=</span> <span class="n">measure_args</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;beta&#39;</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
        <span class="n">A</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">N</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">beta</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">tril</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">N</span><span class="p">)),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">B</span> <span class="o">=</span> <span class="n">ss</span><span class="o">.</span><span class="n">binom</span><span class="p">(</span><span class="n">alpha</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N</span><span class="p">))[:,</span> <span class="kc">None</span><span class="p">]</span>

        <span class="n">L</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mf">.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">ss</span><span class="o">.</span><span class="n">gammaln</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N</span><span class="p">)</span><span class="o">+</span><span class="n">alpha</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">ss</span><span class="o">.</span><span class="n">gammaln</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">)))</span>
        <span class="n">A</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.</span><span class="o">/</span><span class="n">L</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">])</span> <span class="o">*</span> <span class="n">A</span> <span class="o">*</span> <span class="n">L</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">B</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.</span><span class="o">/</span><span class="n">L</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">])</span> <span class="o">*</span> <span class="n">B</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mf">.5</span> <span class="o">*</span> <span class="n">ss</span><span class="o">.</span><span class="n">gammaln</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">alpha</span><span class="p">))</span> <span class="o">*</span> <span class="n">beta</span><span class="o">**</span><span class="p">((</span><span class="mi">1</span><span class="o">-</span><span class="n">alpha</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>
    <span class="c1"># Legendre (translated)</span>
    <span class="k">elif</span> <span class="n">measure</span> <span class="o">==</span> <span class="s1">&#39;legt&#39;</span><span class="p">:</span>
        <span class="n">Q</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="n">R</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">Q</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">**</span> <span class="mf">.5</span>
        <span class="n">j</span><span class="p">,</span> <span class="n">i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span> <span class="n">Q</span><span class="p">)</span>
        <span class="n">A</span> <span class="o">=</span> <span class="n">R</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">i</span> <span class="o">&lt;</span> <span class="n">j</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mf">1.</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="n">i</span><span class="o">-</span><span class="n">j</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">R</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">B</span> <span class="o">=</span> <span class="n">R</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>
        <span class="n">A</span> <span class="o">=</span> <span class="o">-</span><span class="n">A</span>
    <span class="c1"># Legendre (scaled)</span>
    <span class="k">elif</span> <span class="n">measure</span> <span class="o">==</span> <span class="s1">&#39;legs&#39;</span><span class="p">:</span>
        <span class="n">q</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="n">col</span><span class="p">,</span> <span class="n">row</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span>
        <span class="n">r</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">q</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">M</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">row</span> <span class="o">&gt;=</span> <span class="n">col</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">q</span><span class="p">))</span>
        <span class="n">T</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">q</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">A</span> <span class="o">=</span> <span class="n">T</span> <span class="o">@</span> <span class="n">M</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">T</span><span class="p">)</span>
        <span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">T</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>
        <span class="n">B</span> <span class="o">=</span> <span class="n">B</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> <span class="c1"># Otherwise &quot;UserWarning: given NumPY array is not writeable...&quot; after torch.as_tensor(B)</span>
    <span class="k">elif</span> <span class="n">measure</span> <span class="o">==</span> <span class="s1">&#39;fourier&#39;</span><span class="p">:</span>
        <span class="n">freqs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N</span><span class="o">//</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">freqs</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="o">//</span><span class="mi">2</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">A</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">A</span> <span class="o">=</span> <span class="n">A</span> <span class="o">-</span> <span class="n">embed_c2r</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">N</span><span class="o">//</span><span class="mi">2</span><span class="p">,</span> <span class="n">N</span><span class="o">//</span><span class="mi">2</span><span class="p">)))</span>
        <span class="n">B</span> <span class="o">=</span> <span class="n">embed_c2r</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">N</span><span class="o">//</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">elif</span> <span class="n">measure</span> <span class="o">==</span> <span class="s1">&#39;random&#39;</span><span class="p">:</span>
        <span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span> <span class="o">/</span> <span class="n">N</span>
        <span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">measure</span> <span class="o">==</span> <span class="s1">&#39;diagonal&#39;</span><span class="p">:</span>
        <span class="n">A</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">)))</span>
        <span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">return</span> <span class="n">A</span><span class="p">,</span> <span class="n">B</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">rank_correction</span><span class="p">(</span><span class="n">measure</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Return low-rank matrix L such that A + L is normal &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">measure</span> <span class="o">==</span> <span class="s1">&#39;legs&#39;</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">rank</span> <span class="o">&gt;=</span> <span class="mi">1</span>
        <span class="n">P</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">.5</span><span class="o">+</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">))</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># (1 N)</span>
    <span class="k">elif</span> <span class="n">measure</span> <span class="o">==</span> <span class="s1">&#39;legt&#39;</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">rank</span> <span class="o">&gt;=</span> <span class="mi">2</span>
        <span class="n">P</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="mi">2</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">))</span> <span class="c1"># (N)</span>
        <span class="n">P0</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">P0</span><span class="p">[</span><span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.</span>
        <span class="n">P1</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">P1</span><span class="p">[</span><span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.</span>
        <span class="n">P</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">P0</span><span class="p">,</span> <span class="n">P1</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># (2 N)</span>
    <span class="k">elif</span> <span class="n">measure</span> <span class="o">==</span> <span class="s1">&#39;lagt&#39;</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">rank</span> <span class="o">&gt;=</span> <span class="mi">1</span>
        <span class="n">P</span> <span class="o">=</span> <span class="mf">.5</span><span class="o">**</span><span class="mf">.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">measure</span> <span class="o">==</span> <span class="s1">&#39;fourier&#39;</span><span class="p">:</span>
        <span class="n">P</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span> <span class="c1"># (N)</span>
        <span class="n">P0</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">P0</span><span class="p">[</span><span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.</span>
        <span class="n">P1</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">P1</span><span class="p">[</span><span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.</span>
        <span class="n">P</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">P0</span><span class="p">,</span> <span class="n">P1</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># (2 N)</span>
    <span class="k">else</span><span class="p">:</span> <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="n">d</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">rank</span> <span class="o">&gt;</span> <span class="n">d</span><span class="p">:</span>
        <span class="n">P</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">P</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">rank</span><span class="o">-</span><span class="n">d</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># (rank N)</span>
    <span class="k">return</span> <span class="n">P</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">nplr</span><span class="p">(</span><span class="n">measure</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Return w, p, q, V, B such that</span>
<span class="sd">    (w - p q^*, B) is unitarily equivalent to the original HiPPO A, B by the matrix V</span>
<span class="sd">    i.e. A = V[w - p q^*]V^*, B = V B</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">float</span> <span class="ow">or</span> <span class="n">torch</span><span class="o">.</span><span class="n">cfloat</span>
    <span class="k">if</span> <span class="n">measure</span> <span class="o">==</span> <span class="s1">&#39;random&#39;</span><span class="p">:</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cfloat</span> <span class="k">if</span> <span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">float</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">cdouble</span>
        <span class="c1"># w = torch.randn(N//2, dtype=dtype)</span>
        <span class="n">w</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="o">//</span><span class="mi">2</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span><span class="n">j</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="o">//</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">P</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">N</span><span class="o">//</span><span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">B</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="o">//</span><span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">V</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="n">N</span><span class="o">//</span><span class="mi">2</span><span class="p">]</span> <span class="c1"># Only used in testing</span>
        <span class="k">return</span> <span class="n">w</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">V</span>

    <span class="n">A</span><span class="p">,</span> <span class="n">B</span> <span class="o">=</span> <span class="n">transition</span><span class="p">(</span><span class="n">measure</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span> <span class="c1"># (N, N)</span>
    <span class="n">B</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="c1"># (N,)</span>

    <span class="n">P</span> <span class="o">=</span> <span class="n">rank_correction</span><span class="p">(</span><span class="n">measure</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="n">rank</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">AP</span> <span class="o">=</span> <span class="n">A</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">P</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span><span class="o">*</span><span class="n">P</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">w</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eig</span><span class="p">(</span><span class="n">AP</span><span class="p">)</span> <span class="c1"># (..., N) (..., N, N)</span>
    <span class="c1"># V w V^{-1} = A</span>

    <span class="c1"># Only keep one of the conjugate pairs</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">w</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
    <span class="n">V</span> <span class="o">=</span> <span class="n">V</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>

    <span class="n">V_inv</span> <span class="o">=</span> <span class="n">V</span><span class="o">.</span><span class="n">conj</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span>

    <span class="n">B</span> <span class="o">=</span> <span class="n">contract</span><span class="p">(</span><span class="s1">&#39;ij, j -&gt; i&#39;</span><span class="p">,</span> <span class="n">V_inv</span><span class="p">,</span> <span class="n">B</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">V</span><span class="p">))</span> <span class="c1"># V^* B</span>
    <span class="n">P</span> <span class="o">=</span> <span class="n">contract</span><span class="p">(</span><span class="s1">&#39;ij, ...j -&gt; ...i&#39;</span><span class="p">,</span> <span class="n">V_inv</span><span class="p">,</span> <span class="n">P</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">V</span><span class="p">))</span> <span class="c1"># V^* P</span>


    <span class="k">return</span> <span class="n">w</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">V</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">bilinear</span><span class="p">(</span><span class="n">dt</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    dt: (...) timescales</span>
<span class="sd">    A: (... N N)</span>
<span class="sd">    B: (... N)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">N</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">I</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">N</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
    <span class="n">A_backwards</span> <span class="o">=</span> <span class="n">I</span> <span class="o">-</span> <span class="n">dt</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">A</span>
    <span class="n">A_forwards</span> <span class="o">=</span> <span class="n">I</span> <span class="o">+</span> <span class="n">dt</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">A</span>

    <span class="k">if</span> <span class="n">B</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dB</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">dB</span> <span class="o">=</span> <span class="n">dt</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span>
            <span class="n">A_backwards</span><span class="p">,</span> <span class="n">B</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># (... N)</span>

    <span class="n">dA</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">A_backwards</span><span class="p">,</span> <span class="n">A_forwards</span><span class="p">)</span>  <span class="c1"># (... N N)</span>
    <span class="k">return</span> <span class="n">dA</span><span class="p">,</span> <span class="n">dB</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SSKernelNPLR</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Stores a representation of and computes the SSKernel function K_L(A^dt, B^dt, C) corresponding to a discretized state space, where A is Normal + Low Rank (NPLR)</span>
<span class="sd">    The class name stands for &#39;State-Space SSKernel for Normal Plus Low-Rank&#39;.</span>
<span class="sd">    The parameters of this function are as follows.</span>
<span class="sd">    A: (... N N) the state matrix</span>
<span class="sd">    B: (... N) input matrix</span>
<span class="sd">    C: (... N) output matrix</span>
<span class="sd">    dt: (...) timescales / discretization step size</span>
<span class="sd">    p, q: (... P N) low-rank correction to A, such that Ap=A+pq^T is a normal matrix</span>
<span class="sd">    The forward pass of this Module returns:</span>
<span class="sd">    (... L) that represents represents FFT SSKernel_L(A^dt, B^dt, C)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">_setup_C</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">double_length</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Construct C~ from C</span>
<span class="sd">        double_length: current C is for length L, convert it to length 2L</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">C</span> <span class="o">=</span> <span class="n">_r2c</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">C</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setup_state</span><span class="p">()</span>
        <span class="n">dA_L</span> <span class="o">=</span> <span class="n">power</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dA</span><span class="p">)</span>
        <span class="c1"># Multiply C by I - dA_L</span>
        <span class="n">C_</span> <span class="o">=</span> <span class="n">_conj</span><span class="p">(</span><span class="n">C</span><span class="p">)</span>
        <span class="n">prod</span> <span class="o">=</span> <span class="n">contract</span><span class="p">(</span><span class="s2">&quot;h m n, c h n -&gt; c h m&quot;</span><span class="p">,</span> <span class="n">dA_L</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">),</span> <span class="n">C_</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">double_length</span><span class="p">:</span> <span class="n">prod</span> <span class="o">=</span> <span class="o">-</span><span class="n">prod</span> <span class="c1"># Multiply by I + dA_L instead</span>
        <span class="n">C_</span> <span class="o">=</span> <span class="n">C_</span> <span class="o">-</span> <span class="n">prod</span>
        <span class="n">C_</span> <span class="o">=</span> <span class="n">C_</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">N</span><span class="p">]</span> <span class="c1"># Take conjugate pairs again</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">C</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">_c2r</span><span class="p">(</span><span class="n">C_</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">double_length</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">L</span> <span class="o">*=</span> <span class="mi">2</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_omega</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">C</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">C</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_omega</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Calculate (and cache) FFT nodes and their &quot;unprocessed&quot; them with the bilinear transform</span>
<span class="sd">        This should be called everytime the internal length self.L changes &quot;&quot;&quot;</span>
        <span class="n">omega</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="n">j</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="p">(</span><span class="n">L</span><span class="p">)),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span>
        <span class="p">)</span>  <span class="c1"># \omega_{2L}</span>
        <span class="n">omega</span> <span class="o">=</span> <span class="n">omega</span> <span class="o">**</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">L</span> <span class="o">//</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">omega</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">omega</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">cache</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;omega&quot;</span><span class="p">,</span> <span class="n">_c2r</span><span class="p">(</span><span class="n">omega</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;z&quot;</span><span class="p">,</span> <span class="n">_c2r</span><span class="p">(</span><span class="n">z</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">omega</span><span class="p">,</span> <span class="n">z</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">L</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">log_dt</span><span class="p">,</span>
        <span class="n">hurwitz</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">trainable</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">lr</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">tie_state</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">length_correction</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        L: Maximum length; this module computes an SSM kernel of length L</span>
<span class="sd">        w: (N)</span>
<span class="sd">        p: (r, N) low-rank correction to A</span>
<span class="sd">        q: (r, N)</span>
<span class="sd">        A represented by diag(w) - pq^*</span>
<span class="sd">        B: (N)</span>
<span class="sd">        dt: (H) timescale per feature</span>
<span class="sd">        C: (H, C, N) system is 1-D to c-D (channels)</span>
<span class="sd">        hurwitz: tie pq and ensure w has negative real part</span>
<span class="sd">        trainable: toggle which of the parameters is trainable</span>
<span class="sd">        lr: add hook to set lr of hippo parameters specially (everything besides C)</span>
<span class="sd">        tie_state: tie all state parameters across the H hidden features</span>
<span class="sd">        length_correction: multiply C by (I - dA^L) - can be turned off when L is large for slight speedup at initialization (only relevant when N large as well)</span>
<span class="sd">        Note: tensor shape N here denotes half the true state size, because of conjugate symmetry</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hurwitz</span> <span class="o">=</span> <span class="n">hurwitz</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tie_state</span> <span class="o">=</span> <span class="n">tie_state</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>

        <span class="c1"># Rank of low-rank correction</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
        <span class="k">assert</span> <span class="n">w</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">P</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">B</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">C</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">H</span> <span class="o">=</span> <span class="n">log_dt</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">N</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Broadcast everything to correct shapes</span>
        <span class="n">C</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">broadcast_shapes</span><span class="p">(</span><span class="n">C</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">H</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">N</span><span class="p">)))</span> <span class="c1"># (H, C, N)</span>
        <span class="n">H</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tie_state</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">H</span>
        <span class="n">B</span> <span class="o">=</span> <span class="n">repeat</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="s1">&#39;n -&gt; 1 h n&#39;</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="n">H</span><span class="p">)</span>
        <span class="n">P</span> <span class="o">=</span> <span class="n">repeat</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="s1">&#39;r n -&gt; r h n&#39;</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="n">H</span><span class="p">)</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">repeat</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="s1">&#39;n -&gt; h n&#39;</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="n">H</span><span class="p">)</span>

        <span class="c1"># Cache Fourier nodes every time we set up a desired length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">L</span> <span class="o">=</span> <span class="n">L</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">L</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_omega</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">C</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">C</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Register parameters</span>
        <span class="c1"># C is a regular parameter, not state</span>
        <span class="c1"># self.C = nn.Parameter(_c2r(C.conj().resolve_conj()))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">C</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">_c2r</span><span class="p">(</span><span class="n">_resolve_conj</span><span class="p">(</span><span class="n">C</span><span class="p">)))</span>
        <span class="n">train</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="n">trainable</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="n">trainable</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="n">trainable</span> <span class="o">==</span> <span class="kc">False</span><span class="p">:</span> <span class="n">trainable</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="n">trainable</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span> <span class="n">trainable</span><span class="p">,</span> <span class="n">train</span> <span class="o">=</span> <span class="p">{},</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s2">&quot;log_dt&quot;</span><span class="p">,</span> <span class="n">log_dt</span><span class="p">,</span> <span class="n">trainable</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;dt&#39;</span><span class="p">,</span> <span class="n">train</span><span class="p">),</span> <span class="n">lr</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s2">&quot;B&quot;</span><span class="p">,</span> <span class="n">_c2r</span><span class="p">(</span><span class="n">B</span><span class="p">),</span> <span class="n">trainable</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="n">train</span><span class="p">),</span> <span class="n">lr</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s2">&quot;P&quot;</span><span class="p">,</span> <span class="n">_c2r</span><span class="p">(</span><span class="n">P</span><span class="p">),</span> <span class="n">trainable</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;P&#39;</span><span class="p">,</span> <span class="n">train</span><span class="p">),</span> <span class="n">lr</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">hurwitz</span><span class="p">:</span>
            <span class="n">log_w_real</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="o">-</span><span class="n">w</span><span class="o">.</span><span class="n">real</span> <span class="o">+</span> <span class="mf">1e-3</span><span class="p">)</span> <span class="c1"># Some of the HiPPO methods have real part 0</span>
            <span class="n">w_imag</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">imag</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s2">&quot;log_w_real&quot;</span><span class="p">,</span> <span class="n">log_w_real</span><span class="p">,</span> <span class="n">trainable</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">lr</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s2">&quot;w_imag&quot;</span><span class="p">,</span> <span class="n">w_imag</span><span class="p">,</span> <span class="n">trainable</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="n">train</span><span class="p">),</span> <span class="n">lr</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Q</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="n">_c2r</span><span class="p">(</span><span class="n">w</span><span class="p">),</span> <span class="n">trainable</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="n">train</span><span class="p">),</span> <span class="n">lr</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
            <span class="c1"># self.register(&quot;Q&quot;, _c2r(P.clone().conj().resolve_conj()), trainable.get(&#39;P&#39;, train), lr, 0.0)</span>
            <span class="n">Q</span> <span class="o">=</span> <span class="n">_resolve_conj</span><span class="p">(</span><span class="n">P</span><span class="o">.</span><span class="n">clone</span><span class="p">())</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s2">&quot;Q&quot;</span><span class="p">,</span> <span class="n">_c2r</span><span class="p">(</span><span class="n">Q</span><span class="p">),</span> <span class="n">trainable</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;P&#39;</span><span class="p">,</span> <span class="n">train</span><span class="p">),</span> <span class="n">lr</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">length_correction</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_setup_C</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_w</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Get the internal w (diagonal) parameter</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">hurwitz</span><span class="p">:</span>
            <span class="n">w_real</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_w_real</span><span class="p">)</span>
            <span class="n">w_imag</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_imag</span>
            <span class="n">w</span> <span class="o">=</span> <span class="n">w_real</span> <span class="o">+</span> <span class="mi">1</span><span class="n">j</span> <span class="o">*</span> <span class="n">w_imag</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">w</span> <span class="o">=</span> <span class="n">_r2c</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w</span><span class="p">)</span>  <span class="c1"># (..., N)</span>
        <span class="k">return</span> <span class="n">w</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">rate</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">L</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        state: (..., s, N) extra tensor that augments B</span>
<span class="sd">        rate: sampling rate factor</span>
<span class="sd">        returns: (..., c+s, L)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Handle sampling rate logic</span>
        <span class="c1"># The idea is that this kernel&#39;s length (in continuous units) is self.L, while we are asked to provide a kernel of length L at (relative) sampling rate rate</span>
        <span class="c1"># If either are not passed in, assume we&#39;re not asked to change the scale of our kernel</span>
        <span class="k">assert</span> <span class="ow">not</span> <span class="p">(</span><span class="n">rate</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">L</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">rate</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">rate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">L</span> <span class="o">/</span> <span class="n">L</span>
        <span class="k">if</span> <span class="n">L</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">L</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span> <span class="o">/</span> <span class="n">rate</span><span class="p">)</span>

        <span class="c1"># Increase the internal length if needed</span>
        <span class="k">while</span> <span class="n">rate</span> <span class="o">*</span> <span class="n">L</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">double_length</span><span class="p">()</span>

        <span class="n">dt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_dt</span><span class="p">)</span> <span class="o">*</span> <span class="n">rate</span>
        <span class="n">B</span> <span class="o">=</span> <span class="n">_r2c</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">B</span><span class="p">)</span>
        <span class="n">C</span> <span class="o">=</span> <span class="n">_r2c</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">C</span><span class="p">)</span>
        <span class="n">P</span> <span class="o">=</span> <span class="n">_r2c</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">P</span><span class="p">)</span>
        <span class="n">Q</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">conj</span><span class="p">()</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">Q</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">_r2c</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Q</span><span class="p">)</span>
        <span class="n">w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_w</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">rate</span> <span class="o">==</span> <span class="mf">1.0</span><span class="p">:</span>
            <span class="c1"># Use cached FFT nodes</span>
            <span class="n">omega</span><span class="p">,</span> <span class="n">z</span> <span class="o">=</span> <span class="n">_r2c</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">omega</span><span class="p">),</span> <span class="n">_r2c</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">z</span><span class="p">)</span>  <span class="c1"># (..., L)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">omega</span><span class="p">,</span> <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_omega</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="o">/</span><span class="n">rate</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">w</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">w</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tie_state</span><span class="p">:</span>
            <span class="n">B</span> <span class="o">=</span> <span class="n">repeat</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="s1">&#39;... 1 n -&gt; ... h n&#39;</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">H</span><span class="p">)</span>
            <span class="n">P</span> <span class="o">=</span> <span class="n">repeat</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="s1">&#39;... 1 n -&gt; ... h n&#39;</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">H</span><span class="p">)</span>
            <span class="n">Q</span> <span class="o">=</span> <span class="n">repeat</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span> <span class="s1">&#39;... 1 n -&gt; ... h n&#39;</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">H</span><span class="p">)</span>

        <span class="c1"># Augment B</span>
        <span class="k">if</span> <span class="n">state</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Have to &quot;unbilinear&quot; the state to put it into the same &quot;type&quot; as B</span>
            <span class="c1"># Compute 1/dt * (I + dt/2 A) @ state</span>

            <span class="c1"># Can do this without expanding (maybe minor speedup using conj symmetry in theory), but it&#39;s easier to read this way</span>
            <span class="n">s</span> <span class="o">=</span> <span class="n">_conj</span><span class="p">(</span><span class="n">state</span><span class="p">)</span> <span class="k">if</span> <span class="n">state</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">N</span> <span class="k">else</span> <span class="n">state</span> <span class="c1"># (B H N)</span>
            <span class="n">sA</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">s</span> <span class="o">*</span> <span class="n">_conj</span><span class="p">(</span><span class="n">w</span><span class="p">)</span> <span class="c1"># (B H N)</span>
                <span class="o">-</span> <span class="n">contract</span><span class="p">(</span><span class="s1">&#39;bhm, rhm, rhn -&gt; bhn&#39;</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">_conj</span><span class="p">(</span><span class="n">Q</span><span class="p">),</span> <span class="n">_conj</span><span class="p">(</span><span class="n">P</span><span class="p">))</span>
            <span class="p">)</span>
            <span class="n">s</span> <span class="o">=</span> <span class="n">s</span> <span class="o">/</span> <span class="n">dt</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">sA</span> <span class="o">/</span> <span class="mi">2</span>
            <span class="n">s</span> <span class="o">=</span> <span class="n">s</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">N</span><span class="p">]</span>

            <span class="n">B</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">s</span><span class="p">,</span> <span class="n">B</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">3</span><span class="p">)</span>  <span class="c1"># (s+1, H, N)</span>

        <span class="c1"># Incorporate dt into A</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">w</span> <span class="o">*</span> <span class="n">dt</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (H N)</span>

        <span class="c1"># Stack B and p, C and q for convenient batching</span>
        <span class="n">B</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">B</span><span class="p">,</span> <span class="n">P</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">3</span><span class="p">)</span> <span class="c1"># (s+1+r, H, N)</span>
        <span class="n">C</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">C</span><span class="p">,</span> <span class="n">Q</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">3</span><span class="p">)</span> <span class="c1"># (c+r, H, N)</span>

        <span class="c1"># Incorporate B and C batch dimensions</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">B</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">)</span> <span class="o">*</span> <span class="n">C</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">)</span>  <span class="c1"># (s+1+r, c+r, H, N)</span>
        <span class="c1"># w = w[None, None, ...]  # (1, 1, H, N)</span>
        <span class="c1"># z = z[None, None, None, ...]  # (1, 1, 1, L)</span>

        <span class="c1"># Calculate resolvent at omega</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">cauchy_conj</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">r</span> <span class="o">*</span> <span class="n">dt</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">]</span>  <span class="c1"># (S+1+R, C+R, H, L)</span>

        <span class="c1"># Low-rank Woodbury correction</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">k_f</span> <span class="o">=</span> <span class="n">r</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">-</span> <span class="n">r</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">*</span> <span class="n">r</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">r</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">:,</span> <span class="p">:,</span> <span class="p">:])</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">r00</span> <span class="o">=</span> <span class="n">r</span><span class="p">[:</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="p">,</span> <span class="p">:</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>
            <span class="n">r01</span> <span class="o">=</span> <span class="n">r</span><span class="p">[:</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="p">,</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span>
            <span class="n">r10</span> <span class="o">=</span> <span class="n">r</span><span class="p">[</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="p">:,</span> <span class="p">:</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>
            <span class="n">r11</span> <span class="o">=</span> <span class="n">r</span><span class="p">[</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="p">:,</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span>
            <span class="n">det</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">r11</span><span class="p">[:</span><span class="mi">1</span><span class="p">,</span> <span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:])</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">r11</span><span class="p">[</span><span class="mi">1</span><span class="p">:,</span> <span class="mi">1</span><span class="p">:,</span> <span class="p">:,</span> <span class="p">:])</span> <span class="o">-</span> <span class="n">r11</span><span class="p">[:</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">*</span> <span class="n">r11</span><span class="p">[</span><span class="mi">1</span><span class="p">:,</span> <span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>
            <span class="n">s</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">r01</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">r11</span><span class="p">[</span><span class="mi">1</span><span class="p">:,</span> <span class="mi">1</span><span class="p">:,</span> <span class="p">:,</span> <span class="p">:])</span> <span class="o">*</span> <span class="n">r10</span><span class="p">[:</span><span class="mi">1</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span>
                <span class="o">+</span> <span class="n">r01</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">r11</span><span class="p">[:</span><span class="mi">1</span><span class="p">,</span> <span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:])</span> <span class="o">*</span> <span class="n">r10</span><span class="p">[</span><span class="mi">1</span><span class="p">:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span>
                <span class="o">-</span> <span class="n">r01</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">*</span> <span class="p">(</span><span class="n">r11</span><span class="p">[:</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">:,</span> <span class="p">:,</span> <span class="p">:])</span> <span class="o">*</span> <span class="n">r10</span><span class="p">[</span><span class="mi">1</span><span class="p">:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span>
                <span class="o">-</span> <span class="n">r01</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">*</span> <span class="p">(</span><span class="n">r11</span><span class="p">[</span><span class="mi">1</span><span class="p">:,</span> <span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:])</span> <span class="o">*</span> <span class="n">r10</span><span class="p">[:</span><span class="mi">1</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span>
            <span class="p">)</span>
            <span class="n">s</span> <span class="o">=</span> <span class="n">s</span> <span class="o">/</span> <span class="n">det</span>
            <span class="n">k_f</span> <span class="o">=</span> <span class="n">r00</span> <span class="o">-</span> <span class="n">s</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">r00</span> <span class="o">=</span> <span class="n">r</span><span class="p">[:</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="p">,</span> <span class="p">:</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>
            <span class="n">r01</span> <span class="o">=</span> <span class="n">r</span><span class="p">[:</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="p">,</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span>
            <span class="n">r10</span> <span class="o">=</span> <span class="n">r</span><span class="p">[</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="p">:,</span> <span class="p">:</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>
            <span class="n">r11</span> <span class="o">=</span> <span class="n">r</span><span class="p">[</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="p">:,</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span>
            <span class="n">r11</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">r11</span><span class="p">,</span> <span class="s2">&quot;a b h n -&gt; h n a b&quot;</span><span class="p">)</span>
            <span class="n">r11</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">r</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="o">+</span> <span class="n">r11</span><span class="p">)</span>
            <span class="n">r11</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">r11</span><span class="p">,</span> <span class="s2">&quot;h n a b -&gt; a b h n&quot;</span><span class="p">)</span>
            <span class="n">k_f</span> <span class="o">=</span> <span class="n">r00</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;i j h n, j k h n, k l h n -&gt; i l h n&quot;</span><span class="p">,</span> <span class="n">r01</span><span class="p">,</span> <span class="n">r11</span><span class="p">,</span> <span class="n">r10</span><span class="p">)</span>

        <span class="c1"># Final correction for the bilinear transform</span>
        <span class="n">k_f</span> <span class="o">=</span> <span class="n">k_f</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">omega</span><span class="p">)</span>

        <span class="c1"># Move from frequency to coefficients</span>
        <span class="n">k</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">irfft</span><span class="p">(</span><span class="n">k_f</span><span class="p">)</span>  <span class="c1"># (S+1, C, H, L)</span>

        <span class="c1"># Truncate to target length</span>
        <span class="n">k</span> <span class="o">=</span> <span class="n">k</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="n">L</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">state</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">k_state</span> <span class="o">=</span> <span class="n">k</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span>  <span class="c1"># (S, C, H, L)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">k_state</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">k_B</span> <span class="o">=</span> <span class="n">k</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="c1"># (C H L)</span>
        <span class="k">return</span> <span class="n">k_B</span><span class="p">,</span> <span class="n">k_state</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">double_length</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setup_C</span><span class="p">(</span><span class="n">double_length</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_setup_linear</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Create parameters that allow fast linear stepping of state &quot;&quot;&quot;</span>
        <span class="n">w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_w</span><span class="p">()</span>
        <span class="n">B</span> <span class="o">=</span> <span class="n">_r2c</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">B</span><span class="p">)</span> <span class="c1"># (H N)</span>
        <span class="n">P</span> <span class="o">=</span> <span class="n">_r2c</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">P</span><span class="p">)</span>
        <span class="n">Q</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">conj</span><span class="p">()</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">Q</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">_r2c</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Q</span><span class="p">)</span>

        <span class="c1"># Prepare Linear stepping</span>
        <span class="n">dt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_dt</span><span class="p">)</span>
        <span class="n">D</span> <span class="o">=</span> <span class="p">(</span><span class="mf">2.0</span> <span class="o">/</span> <span class="n">dt</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">w</span><span class="p">)</span><span class="o">.</span><span class="n">reciprocal</span><span class="p">()</span>  <span class="c1"># (H, N)</span>
        <span class="n">R</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">w</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">w</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="n">contract</span><span class="p">(</span><span class="s1">&#39;r h n, h n, s h n -&gt; h r s&#39;</span><span class="p">,</span> <span class="n">Q</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">P</span><span class="p">)</span><span class="o">.</span><span class="n">real</span><span class="p">)</span> <span class="c1"># (H r r)</span>
        <span class="n">Q_D</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">Q</span><span class="o">*</span><span class="n">D</span><span class="p">,</span> <span class="s1">&#39;r h n -&gt; h r n&#39;</span><span class="p">)</span>
        <span class="n">R</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">R</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">Q_D</span><span class="p">),</span> <span class="n">Q_D</span><span class="p">)</span> <span class="c1"># (H r N)</span>
        <span class="n">R</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="s1">&#39;h r n -&gt; r h n&#39;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">step_params</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;D&quot;</span><span class="p">:</span> <span class="n">D</span><span class="p">,</span> <span class="c1"># (H N)</span>
            <span class="s2">&quot;R&quot;</span><span class="p">:</span> <span class="n">R</span><span class="p">,</span> <span class="c1"># (r H N)</span>
            <span class="s2">&quot;P&quot;</span><span class="p">:</span> <span class="n">P</span><span class="p">,</span> <span class="c1"># (r H N)</span>
            <span class="s2">&quot;Q&quot;</span><span class="p">:</span> <span class="n">Q</span><span class="p">,</span> <span class="c1"># (r H N)</span>
            <span class="s2">&quot;B&quot;</span><span class="p">:</span> <span class="n">B</span><span class="p">,</span> <span class="c1"># (1 H N)</span>
            <span class="s2">&quot;E&quot;</span><span class="p">:</span> <span class="mf">2.0</span> <span class="o">/</span> <span class="n">dt</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">w</span><span class="p">,</span> <span class="c1"># (H N)</span>
        <span class="p">}</span>

    <span class="k">def</span> <span class="nf">_step_state_linear</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Version of the step function that has time O(N) instead of O(N^2) per step, which takes advantage of the DPLR form and bilinear discretization.</span>
<span class="sd">        Unfortunately, as currently implemented it&#39;s about 2x slower because it calls several sequential operations. Perhaps a fused CUDA kernel implementation would be much faster</span>
<span class="sd">        u: (H) input</span>
<span class="sd">        state: (H, N/2) state with conjugate pairs</span>
<span class="sd">          Optionally, the state can have last dimension N</span>
<span class="sd">        Returns: same shape as state</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">C</span> <span class="o">=</span> <span class="n">_r2c</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">C</span><span class="p">)</span> <span class="c1"># View used for dtype/device</span>

        <span class="k">if</span> <span class="n">u</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="c1"># Special case used to find dA</span>
            <span class="n">u</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">H</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">C</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">C</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">state</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="c1"># Special case used to find dB</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">H</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">N</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">C</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">C</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="n">step_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">step_params</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">state</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">N</span><span class="p">:</span> <span class="c1"># Only store half of the conjugate pairs; should be true by default</span>
            <span class="c1"># There should be a slightly faster way using conjugate symmetry</span>
            <span class="n">contract_fn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">p</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">contract</span><span class="p">(</span><span class="s1">&#39;r h n, r h m, ... h m -&gt; ... h n&#39;</span><span class="p">,</span> <span class="n">_conj</span><span class="p">(</span><span class="n">p</span><span class="p">),</span> <span class="n">_conj</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">_conj</span><span class="p">(</span><span class="n">y</span><span class="p">))[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">N</span><span class="p">]</span> <span class="c1"># inner outer product</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">state</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">N</span>
            <span class="n">step_params</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">_conj</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">step_params</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
            <span class="c1"># TODO worth setting up a contract_expression in default_state if we want to use this at inference time for stepping</span>
            <span class="n">contract_fn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">p</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">contract</span><span class="p">(</span><span class="s1">&#39;r h n, r h m, ... h m -&gt; ... h n&#39;</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="c1"># inner outer product</span>
        <span class="n">D</span> <span class="o">=</span> <span class="n">step_params</span><span class="p">[</span><span class="s2">&quot;D&quot;</span><span class="p">]</span>  <span class="c1"># (H N)</span>
        <span class="n">E</span> <span class="o">=</span> <span class="n">step_params</span><span class="p">[</span><span class="s2">&quot;E&quot;</span><span class="p">]</span>  <span class="c1"># (H N)</span>
        <span class="n">R</span> <span class="o">=</span> <span class="n">step_params</span><span class="p">[</span><span class="s2">&quot;R&quot;</span><span class="p">]</span>  <span class="c1"># (r H N)</span>
        <span class="n">P</span> <span class="o">=</span> <span class="n">step_params</span><span class="p">[</span><span class="s2">&quot;P&quot;</span><span class="p">]</span>  <span class="c1"># (r H N)</span>
        <span class="n">Q</span> <span class="o">=</span> <span class="n">step_params</span><span class="p">[</span><span class="s2">&quot;Q&quot;</span><span class="p">]</span>  <span class="c1"># (r H N)</span>
        <span class="n">B</span> <span class="o">=</span> <span class="n">step_params</span><span class="p">[</span><span class="s2">&quot;B&quot;</span><span class="p">]</span>  <span class="c1"># (1 H N)</span>

        <span class="n">new_state</span> <span class="o">=</span> <span class="n">E</span> <span class="o">*</span> <span class="n">state</span> <span class="o">-</span> <span class="n">contract_fn</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">Q</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span> <span class="c1"># (B H N)</span>
        <span class="n">new_state</span> <span class="o">=</span> <span class="n">new_state</span> <span class="o">+</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">B</span> <span class="o">*</span> <span class="n">u</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (B H N)</span>
        <span class="n">new_state</span> <span class="o">=</span> <span class="n">D</span> <span class="o">*</span> <span class="p">(</span><span class="n">new_state</span> <span class="o">-</span> <span class="n">contract_fn</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">R</span><span class="p">,</span> <span class="n">new_state</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">new_state</span>

    <span class="k">def</span> <span class="nf">_setup_state</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Construct dA and dB for discretized state equation &quot;&quot;&quot;</span>

        <span class="c1"># Construct dA and dB by using the stepping</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setup_linear</span><span class="p">()</span>
        <span class="n">C</span> <span class="o">=</span> <span class="n">_r2c</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">C</span><span class="p">)</span> <span class="c1"># Just returns a view that we use for finding dtype/device</span>

        <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">N</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">C</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">C</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># (N 1 N)</span>
        <span class="n">dA</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_step_state_linear</span><span class="p">(</span><span class="n">state</span><span class="o">=</span><span class="n">state</span><span class="p">)</span>
        <span class="n">dA</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">dA</span><span class="p">,</span> <span class="s2">&quot;n h m -&gt; h m n&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dA</span> <span class="o">=</span> <span class="n">dA</span> <span class="c1"># (H N N)</span>

        <span class="n">u</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">new_ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">H</span><span class="p">)</span>
        <span class="n">dB</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_step_state_linear</span><span class="p">(</span><span class="n">u</span><span class="o">=</span><span class="n">u</span><span class="p">)</span>
        <span class="n">dB</span> <span class="o">=</span> <span class="n">_conj</span><span class="p">(</span><span class="n">dB</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dB</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">dB</span><span class="p">,</span> <span class="s1">&#39;1 h n -&gt; h n&#39;</span><span class="p">)</span> <span class="c1"># (H N)</span>

    <span class="k">def</span> <span class="nf">_step_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Must be called after self.default_state() is used to construct an initial state!  &quot;&quot;&quot;</span>
        <span class="n">next_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_contraction</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dA</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_contraction</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dB</span><span class="p">,</span> <span class="n">u</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">next_state</span>


    <span class="k">def</span> <span class="nf">setup_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;dense&#39;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Set up dA, dB, dC discretized parameters for stepping &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setup_state</span><span class="p">()</span>

        <span class="c1"># Calculate original C</span>
        <span class="n">dA_L</span> <span class="o">=</span> <span class="n">power</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dA</span><span class="p">)</span>
        <span class="n">I</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dA</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dA_L</span><span class="p">)</span>
        <span class="n">C</span> <span class="o">=</span> <span class="n">_conj</span><span class="p">(</span><span class="n">_r2c</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">C</span><span class="p">))</span> <span class="c1"># (H C N)</span>

        <span class="n">dC</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span>
            <span class="n">I</span> <span class="o">-</span> <span class="n">dA_L</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">C</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dC</span> <span class="o">=</span> <span class="n">dC</span>

        <span class="c1"># Do special preprocessing for different step modes</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_step_mode</span> <span class="o">=</span> <span class="n">mode</span>
        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;linear&#39;</span><span class="p">:</span>
            <span class="c1"># Linear case: special step function for the state, we need to handle output</span>
            <span class="c1"># use conjugate symmetry by default, which affects the output projection</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dC</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">dC</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">N</span><span class="p">]</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;diagonal&#39;</span><span class="p">:</span>
            <span class="c1"># Eigendecomposition of the A matrix</span>
            <span class="n">L</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eig</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dA</span><span class="p">)</span>
            <span class="n">V_inv</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">V</span><span class="p">)</span>
            <span class="c1"># Check that the eigendedecomposition is correct</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Diagonalization error:&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">dist</span><span class="p">(</span><span class="n">V</span> <span class="o">@</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag_embed</span><span class="p">(</span><span class="n">L</span><span class="p">)</span> <span class="o">@</span> <span class="n">V_inv</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dA</span><span class="p">))</span>

            <span class="c1"># Change the parameterization to diagonalize</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dA</span> <span class="o">=</span> <span class="n">L</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dB</span> <span class="o">=</span> <span class="n">contract</span><span class="p">(</span><span class="s1">&#39;h n m, h m -&gt; h n&#39;</span><span class="p">,</span> <span class="n">V_inv</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dB</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dC</span> <span class="o">=</span> <span class="n">contract</span><span class="p">(</span><span class="s1">&#39;h n m, c h n -&gt; c h m&#39;</span><span class="p">,</span> <span class="n">V</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dC</span><span class="p">)</span>

        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;dense&#39;</span><span class="p">:</span>
            <span class="k">pass</span>
        <span class="k">else</span><span class="p">:</span> <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;NPLR Kernel step mode must be {&#39;dense&#39; | &#39;linear&#39; | &#39;diagonal&#39;}&quot;</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">default_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">batch_shape</span><span class="p">):</span>
        <span class="n">C</span> <span class="o">=</span> <span class="n">_r2c</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">C</span><span class="p">)</span>
        <span class="n">N</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">H</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>

        <span class="c1"># Cache the tensor contractions we will later do, for efficiency</span>
        <span class="c1"># These are put in this function because they depend on the batch size</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_step_mode</span> <span class="o">!=</span><span class="s1">&#39;linear&#39;</span><span class="p">:</span>
            <span class="n">N</span> <span class="o">*=</span> <span class="mi">2</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_step_mode</span> <span class="o">==</span> <span class="s1">&#39;diagonal&#39;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">state_contraction</span> <span class="o">=</span> <span class="n">contract_expression</span><span class="p">(</span>
                    <span class="s2">&quot;h n, ... h n -&gt; ... h n&quot;</span><span class="p">,</span>
                    <span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">N</span><span class="p">),</span>
                    <span class="n">batch_shape</span> <span class="o">+</span> <span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">N</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Dense (quadratic) case: expand all terms</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">state_contraction</span> <span class="o">=</span> <span class="n">contract_expression</span><span class="p">(</span>
                    <span class="s2">&quot;h m n, ... h n -&gt; ... h m&quot;</span><span class="p">,</span>
                    <span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">N</span><span class="p">),</span>
                    <span class="n">batch_shape</span> <span class="o">+</span> <span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">N</span><span class="p">),</span>
                <span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">input_contraction</span> <span class="o">=</span> <span class="n">contract_expression</span><span class="p">(</span>
                <span class="s2">&quot;h n, ... h -&gt; ... h n&quot;</span><span class="p">,</span>
                <span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">N</span><span class="p">),</span> <span class="c1"># self.dB.shape</span>
                <span class="n">batch_shape</span> <span class="o">+</span> <span class="p">(</span><span class="n">H</span><span class="p">,),</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">output_contraction</span> <span class="o">=</span> <span class="n">contract_expression</span><span class="p">(</span>
            <span class="s2">&quot;c h n, ... h n -&gt; ... c h&quot;</span><span class="p">,</span>
            <span class="p">(</span><span class="n">C</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">H</span><span class="p">,</span> <span class="n">N</span><span class="p">),</span> <span class="c1"># self.dC.shape</span>
            <span class="n">batch_shape</span> <span class="o">+</span> <span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">N</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="o">*</span><span class="n">batch_shape</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">C</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">C</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">state</span>

    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Must have called self.setup_step() and created state with self.default_state() before calling this &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_step_mode</span> <span class="o">==</span> <span class="s1">&#39;linear&#39;</span><span class="p">:</span>
            <span class="n">new_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_step_state_linear</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">new_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_step_state</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_contraction</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dC</span><span class="p">,</span> <span class="n">new_state</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span><span class="p">,</span> <span class="n">new_state</span>

    <span class="k">def</span> <span class="nf">register</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">wd</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Utility method: register a tensor as a buffer or trainable parameter&quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">trainable</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_parameter</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">tensor</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">tensor</span><span class="p">)</span>

        <span class="n">optim</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="n">trainable</span> <span class="ow">and</span> <span class="n">lr</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">optim</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lr</span>
        <span class="k">if</span> <span class="n">trainable</span> <span class="ow">and</span> <span class="n">wd</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">optim</span><span class="p">[</span><span class="s2">&quot;weight_decay&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">wd</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">optim</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">),</span> <span class="s2">&quot;_optim&quot;</span><span class="p">,</span> <span class="n">optim</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">HippoSSKernel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
  
    <span class="sd">&quot;&quot;&quot;Wrapper around SSKernel that generates A, B, C, dt according to HiPPO arguments.</span>
<span class="sd">    The SSKernel is expected to support the interface</span>
<span class="sd">    forward()</span>
<span class="sd">    default_state()</span>
<span class="sd">    setup_step()</span>
<span class="sd">    step()</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">H</span><span class="p">,</span>
        <span class="n">N</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
        <span class="n">L</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">measure</span><span class="o">=</span><span class="s2">&quot;legs&quot;</span><span class="p">,</span>
        <span class="n">rank</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="c1"># 1-dim to C-dim map; can think of C as having separate &quot;heads&quot;</span>
        <span class="n">dt_min</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
        <span class="n">dt_max</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
        <span class="n">trainable</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="c1"># Dictionary of options to train various HiPPO parameters</span>
        <span class="n">lr</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="c1"># Hook to set LR of hippo parameters differently</span>
        <span class="n">length_correction</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="c1"># Multiply by I-A|^L after initialization; can be turned off for initialization speed</span>
        <span class="n">hurwitz</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">tie_state</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="c1"># Tie parameters of HiPPO ODE across the H features</span>
        <span class="n">precision</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="c1"># 1 (single) or 2 (double) for the kernel</span>
        <span class="n">resample</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># If given inputs of different lengths, adjust the sampling rate. Note that L should always be provided in this case, as it assumes that L is the true underlying length of the continuous signal</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">N</span> <span class="o">=</span> <span class="n">N</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">H</span> <span class="o">=</span> <span class="n">H</span>
        <span class="n">L</span> <span class="o">=</span> <span class="n">L</span> <span class="ow">or</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">precision</span> <span class="o">=</span> <span class="n">precision</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">double</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">precision</span> <span class="o">==</span> <span class="mi">2</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">float</span>
        <span class="n">cdtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cfloat</span> <span class="k">if</span> <span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">float</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">cdouble</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rate</span> <span class="o">=</span> <span class="kc">None</span> <span class="k">if</span> <span class="n">resample</span> <span class="k">else</span> <span class="mf">1.0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">channels</span> <span class="o">=</span> <span class="n">channels</span>

        <span class="c1"># Generate dt</span>
        <span class="n">log_dt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">H</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span>
            <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">dt_max</span><span class="p">)</span> <span class="o">-</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">dt_min</span><span class="p">)</span>
        <span class="p">)</span> <span class="o">+</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">dt_min</span><span class="p">)</span>

        <span class="n">w</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">nplr</span><span class="p">(</span><span class="n">measure</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">N</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">C</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">H</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">N</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">cdtype</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="n">SSKernelNPLR</span><span class="p">(</span>
            <span class="n">L</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span>
            <span class="n">log_dt</span><span class="p">,</span>
            <span class="n">hurwitz</span><span class="o">=</span><span class="n">hurwitz</span><span class="p">,</span>
            <span class="n">trainable</span><span class="o">=</span><span class="n">trainable</span><span class="p">,</span>
            <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span>
            <span class="n">tie_state</span><span class="o">=</span><span class="n">tie_state</span><span class="p">,</span>
            <span class="n">length_correction</span><span class="o">=</span><span class="n">length_correction</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">L</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">k</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="p">(</span><span class="n">rate</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">rate</span><span class="p">,</span> <span class="n">L</span><span class="o">=</span><span class="n">L</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">k</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">u</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">u</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span> <span class="n">state</span>

    <span class="k">def</span> <span class="nf">default_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">default_state</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">S4</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">d_model</span><span class="p">,</span>
            <span class="n">d_state</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
            <span class="n">l_max</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="c1"># Maximum length of sequence. Fine if not provided: the kernel will keep doubling in length until longer than sequence. However, this can be marginally slower if the true length is not a power of 2</span>
            <span class="n">channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="c1"># maps 1-dim to C-dim</span>
            <span class="n">bidirectional</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="c1"># Arguments for FF</span>
            <span class="n">postact</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="c1"># activation after FF</span>
            <span class="n">initializer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="c1"># initializer on FF</span>
            <span class="n">weight_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="c1"># weight normalization on FF</span>
            <span class="n">hyper_act</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="c1"># Use a &quot;hypernetwork&quot; multiplication</span>
            <span class="n">dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
            <span class="n">transposed</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="c1"># axis ordering (B, L, D) or (B, D, L)</span>
            <span class="c1"># SSM Kernel arguments</span>
            <span class="o">**</span><span class="n">kernel_args</span><span class="p">,</span>
        <span class="p">):</span>


        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        d_state: the dimension of the state, also denoted by N</span>
<span class="sd">        l_max: the maximum sequence length, also denoted by L</span>
<span class="sd">          if this is not known at model creation, set l_max=1</span>
<span class="sd">        channels: can be interpreted as a number of &quot;heads&quot;</span>
<span class="sd">        bidirectional: bidirectional</span>
<span class="sd">        dropout: standard dropout argument</span>
<span class="sd">        transposed: choose backbone axis ordering of (B, L, H) or (B, H, L) [B=batch size, L=sequence length, H=hidden dimension]</span>
<span class="sd">        Other options are all experimental and should not need to be configured</span>
<span class="sd">        &quot;&quot;&quot;</span>


        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">h</span> <span class="o">=</span> <span class="n">d_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="o">=</span> <span class="n">d_state</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bidirectional</span> <span class="o">=</span> <span class="n">bidirectional</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">channels</span> <span class="o">=</span> <span class="n">channels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transposed</span> <span class="o">=</span> <span class="n">transposed</span>

        <span class="c1"># optional multiplicative modulation GLU-style</span>
        <span class="c1"># https://arxiv.org/abs/2002.05202</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hyper</span> <span class="o">=</span> <span class="n">hyper_act</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyper</span><span class="p">:</span>
            <span class="n">channels</span> <span class="o">*=</span> <span class="mi">2</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">hyper_activation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">D</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">))</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bidirectional</span><span class="p">:</span>
            <span class="n">channels</span> <span class="o">*=</span> <span class="mi">2</span>


        <span class="c1"># SSM Kernel</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="n">HippoSSKernel</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">,</span> <span class="n">N</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">,</span> <span class="n">L</span><span class="o">=</span><span class="n">l_max</span><span class="p">,</span> <span class="n">channels</span><span class="o">=</span><span class="n">channels</span><span class="p">,</span> <span class="o">**</span><span class="n">kernel_args</span><span class="p">)</span>

        <span class="c1"># Pointwise</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">()</span>
        <span class="n">dropout_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout2d</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transposed</span> <span class="k">else</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">dropout_fn</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span> <span class="k">if</span> <span class="n">dropout</span> <span class="o">&gt;</span> <span class="mf">0.0</span> <span class="k">else</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>

        
        <span class="c1"># position-wise output transform to mix features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_linear</span> <span class="o">=</span> <span class="n">LinearActivation</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">channels</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">,</span>
            <span class="n">transposed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">transposed</span><span class="p">,</span>
            <span class="n">initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">,</span>

            <span class="n">weight_norm</span><span class="o">=</span><span class="n">weight_norm</span><span class="p">,</span>
        <span class="p">)</span>
        
        <span class="c1">#self.time_transformer = get_torch_trans(heads=8, layers=1, channels=self.h)</span>
        
        
        

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span> <span class="c1"># absorbs return_output and transformer src mask</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        u: (B H L) if self.transposed else (B L H)</span>
<span class="sd">        state: (H N) never needed unless you know what you&#39;re doing</span>
<span class="sd">        Returns: same shape as u</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">transposed</span><span class="p">:</span> <span class="n">u</span> <span class="o">=</span> <span class="n">u</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">L</span> <span class="o">=</span> <span class="n">u</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Compute SS Kernel</span>
        <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="p">(</span><span class="n">L</span><span class="o">=</span><span class="n">L</span><span class="p">)</span> <span class="c1"># (C H L) (B C H L)</span>

        <span class="c1"># Convolution</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bidirectional</span><span class="p">:</span>
            <span class="n">k0</span><span class="p">,</span> <span class="n">k1</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="s1">&#39;(s c) h l -&gt; s c h l&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">k</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">k0</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">L</span><span class="p">))</span> \
                    <span class="o">+</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">k1</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span> \

        <span class="n">k_f</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">rfft</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">2</span><span class="o">*</span><span class="n">L</span><span class="p">)</span> <span class="c1"># (C H L)</span>
        <span class="n">u_f</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">rfft</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">2</span><span class="o">*</span><span class="n">L</span><span class="p">)</span> <span class="c1"># (B H L)</span>
        <span class="n">y_f</span> <span class="o">=</span> <span class="n">k_f</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">)</span> <span class="o">*</span> <span class="n">u_f</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">)</span>
        <span class="c1">#y_f = contract(&#39;bhl,chl-&gt;bchl&#39;, u_f, k_f) # k_f.unsqueeze(-4) * u_f.unsqueeze(-3) # (B C H L)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">irfft</span><span class="p">(</span><span class="n">y_f</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">2</span><span class="o">*</span><span class="n">L</span><span class="p">)[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="n">L</span><span class="p">]</span> <span class="c1"># (B C H L)</span>


        <span class="c1"># Compute D term in state space equation - essentially a skip connection</span>
        <span class="c1">#y = y + contract(&#39;bhl,ch-&gt;bchl&#39;, u, self.D) # u.unsqueeze(-3) * self.D.unsqueeze(-1)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">y</span> <span class="o">+</span> <span class="n">u</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">D</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Optional hyper-network multiplication</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyper</span><span class="p">:</span>
            <span class="n">y</span><span class="p">,</span> <span class="n">yh</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="s1">&#39;b (s c) h l -&gt; s b c h l&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyper_activation</span><span class="p">(</span><span class="n">yh</span><span class="p">)</span> <span class="o">*</span> <span class="n">y</span>

        <span class="c1"># Reshape to flatten channels</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="s1">&#39;... c h l -&gt; ... (c h) l&#39;</span><span class="p">)</span>

        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">transposed</span><span class="p">:</span> <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span>

        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_linear</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

        <span class="c1"># ysize = b, k, l, requieres l, b, k </span>
        <span class="c1">#y = self.time_transformer(y.permute(2,0,1)).permute(1,2,0)</span>
            
            
        <span class="k">return</span> <span class="n">y</span><span class="p">,</span> <span class="kc">None</span>
        

    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Step one time step as a recurrent model. Intended to be used during validation.</span>
<span class="sd">        u: (B H)</span>
<span class="sd">        state: (B H N)</span>
<span class="sd">        Returns: output (B H), state (B H N)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span>

        <span class="n">y</span><span class="p">,</span> <span class="n">next_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span> <span class="c1"># (B C H)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">y</span> <span class="o">+</span> <span class="n">u</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">D</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="s1">&#39;... c h -&gt; ... (c h)&#39;</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transposed</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_linear</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_linear</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span><span class="p">,</span> <span class="n">next_state</span>

    <span class="k">def</span> <span class="nf">default_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">batch_shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">default_state</span><span class="p">(</span><span class="o">*</span><span class="n">batch_shape</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">d_state</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">h</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">d_output</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">h</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">state_to_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="k">lambda</span> <span class="n">state</span><span class="p">:</span> <span class="n">rearrange</span><span class="p">(</span><span class="s1">&#39;... h n -&gt; ... (h n)&#39;</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>#Model here</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">S4Layer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="c1">#S4 Layer that can be used as a drop-in replacement for a TransformerEncoder</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">lmax</span><span class="p">,</span> <span class="n">N</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">bidirectional</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">layer_norm</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="n">features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">s4_layer</span>  <span class="o">=</span> <span class="n">S4</span><span class="p">(</span><span class="n">d_model</span><span class="o">=</span><span class="n">features</span><span class="p">,</span> 
                            <span class="n">d_state</span><span class="o">=</span><span class="n">N</span><span class="p">,</span> 
                            <span class="n">l_max</span><span class="o">=</span><span class="n">lmax</span><span class="p">,</span> 
                            <span class="n">bidirectional</span><span class="o">=</span><span class="n">bidirectional</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">norm_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">features</span><span class="p">)</span> <span class="k">if</span> <span class="n">layer_norm</span> <span class="k">else</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout2d</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span> <span class="k">if</span> <span class="n">dropout</span><span class="o">&gt;</span><span class="mi">0</span> <span class="k">else</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SiLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">InstanceNorm2d</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ln</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1">#x has shape seq, batch, feature</span>
        <span class="c1">#x = x.permute((0,1,2)) #batch, feature, seq (as expected from S4 with transposed=True)</span>
        <span class="n">xout</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s4_layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1">#batch, feature, seq</span>
        <span class="n">xout</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">xout</span><span class="p">)</span>
        <span class="n">xout</span> <span class="o">=</span> <span class="n">xout</span> <span class="o">+</span> <span class="n">x</span> <span class="c1"># skip connection   # batch, feature, seq</span>
        <span class="c1">#xout = xout.permute((2,0,1)) # seq, batch, feature</span>
        <span class="c1">#print(xout.shape)</span>
        <span class="n">xout</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_layer</span><span class="p">(</span><span class="n">xout</span><span class="p">[:,</span> <span class="p">:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">xout</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ln</span><span class="p">(</span><span class="n">xout</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">xout</span>
</pre></div>
</div>
</div>
</div>
<p>#Data prep and train classses</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Optimization</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">loss_fn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_losses</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_losses</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="c1"># Sets model to train mode</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1">#ones = torch.ones_like(x)</span>

        <span class="c1">#masked = torch.where(x &gt; 0, ones, 0.)</span>

        <span class="c1">#print(masked)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

        <span class="c1"># Makes predictions</span>
        <span class="n">yhat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># Computes loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">yhat</span><span class="p">)</span>

        <span class="c1"># Computes gradients</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

        <span class="c1"># Updates parameters and zeroes gradients</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="mf">0.25</span><span class="p">)</span>


        <span class="c1"># Returns the loss</span>
        <span class="k">return</span> <span class="n">yhat</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>


    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">n_epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
      <span class="n">early_stopping</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span><span class="n">patience</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>


      <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
          <span class="n">train_pred</span> <span class="o">=</span> <span class="p">[]</span>
          <span class="n">val_pred</span> <span class="o">=</span> <span class="p">[]</span>
          <span class="n">batch_losses</span> <span class="o">=</span> <span class="p">[]</span>
          <span class="n">validation_loss</span> <span class="o">=</span> <span class="mi">0</span>
          <span class="n">training_loss</span> <span class="o">=</span> <span class="mi">0</span>
          <span class="k">for</span> <span class="n">x_batch</span><span class="p">,</span> <span class="n">y_batch</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
              <span class="n">x_batch</span> <span class="o">=</span> <span class="n">x_batch</span><span class="o">.</span><span class="n">view</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_features</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
              <span class="n">y_batch</span> <span class="o">=</span> <span class="n">y_batch</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
              <span class="n">yhat</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_step</span><span class="p">(</span><span class="n">x_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span>
              <span class="n">batch_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
              <span class="n">train_pred</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">yhat</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
          <span class="n">training_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">batch_losses</span><span class="p">)</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">train_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">training_loss</span><span class="p">)</span>

          <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
              <span class="n">batch_val_losses</span> <span class="o">=</span> <span class="p">[]</span>
              <span class="k">for</span> <span class="n">x_val</span><span class="p">,</span> <span class="n">y_val</span> <span class="ow">in</span> <span class="n">val_loader</span><span class="p">:</span>
                  <span class="n">x_val</span> <span class="o">=</span> <span class="n">x_val</span><span class="o">.</span><span class="n">view</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_features</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                  <span class="n">y_val</span> <span class="o">=</span> <span class="n">y_val</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                  <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
                  <span class="n">yhat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x_val</span><span class="p">)</span>
                  <span class="n">val_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">y_val</span><span class="p">,</span> <span class="n">yhat</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                  <span class="n">batch_val_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_loss</span><span class="p">)</span>
                  <span class="n">val_pred</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">yhat</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
              <span class="n">validation_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">batch_val_losses</span><span class="p">)</span>
              <span class="bp">self</span><span class="o">.</span><span class="n">val_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">validation_loss</span><span class="p">)</span>

          <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[</span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">n_epochs</span><span class="si">}</span><span class="s2">] Training loss: </span><span class="si">{</span><span class="n">training_loss</span><span class="si">:</span><span class="s2">.10f</span><span class="si">}</span><span class="se">\t</span><span class="s2"> Validation loss: </span><span class="si">{</span><span class="n">validation_loss</span><span class="si">:</span><span class="s2">.10f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

          <span class="c1"># early stopping</span>
          <span class="n">early_stopping</span><span class="p">(</span><span class="n">validation_loss</span><span class="p">)</span>
          <span class="k">if</span> <span class="n">early_stopping</span><span class="o">.</span><span class="n">early_stop</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;We are at epoch:&quot;</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
            <span class="k">break</span>
      <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">train_pred</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">val_pred</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">plot_losses</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
      <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Training loss&quot;</span><span class="p">)</span>
      <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">val_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Validation loss&quot;</span><span class="p">)</span>
      <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
      <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Losses&quot;</span><span class="p">)</span>
      <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
      <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    

    <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    
      <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
          <span class="n">testPredict</span> <span class="o">=</span> <span class="p">[]</span>
          <span class="n">testValues</span> <span class="o">=</span> <span class="p">[]</span>
          <span class="k">for</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
              <span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">view</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_features</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
              <span class="n">y_test</span> <span class="o">=</span> <span class="n">y_test</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
              <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
              <span class="n">yhat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
              <span class="n">testPredict</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">yhat</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
              <span class="n">testValues</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_test</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>

      <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">testPredict</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">testValues</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># def test_predict(testX, model):</span>
<span class="c1">#     testX = testX.reshape((testX.shape[0], 1, 1, testX.shape[2], seq_size))</span>
<span class="c1">#     testPredict = model.predict(testX)</span>
<span class="c1">#     testScore = math.sqrt(mean_squared_error(testY, testPredict[:, :]))</span>
<span class="c1">#     return testPredict, testScore</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plotting</span> <span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">trainPredict</span><span class="p">,</span> <span class="n">valPredict</span><span class="p">,</span> <span class="n">testPredict</span><span class="p">,</span> <span class="n">fcs</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="c1"># shift train predictions for plotting</span>
<span class="c1">#we must shift the predictions so that they align on the x-axis with the original dataset. </span>
    <span class="n">ext</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">if</span> <span class="n">fcs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">ext</span> <span class="o">=</span> <span class="n">fcs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">trainPredictPlot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">dataset</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">ext</span><span class="p">,</span> <span class="n">dataset</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">trainPredictPlot</span><span class="p">[:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
    <span class="n">trainPredictPlot</span><span class="p">[</span><span class="n">seq_size</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span><span class="nb">len</span><span class="p">(</span><span class="n">trainPredict</span><span class="p">)</span><span class="o">+</span><span class="n">seq_size</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">trainPredict</span>

    <span class="c1"># shift val predictions for plotting</span>
    <span class="n">valPredictPlot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">dataset</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">ext</span><span class="p">,</span> <span class="n">dataset</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">valPredictPlot</span><span class="p">[:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
    <span class="n">valPredictPlot</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">trainPredict</span><span class="p">)</span><span class="o">+</span><span class="p">(</span><span class="n">seq_size</span><span class="o">*</span><span class="mi">2</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span><span class="nb">len</span><span class="p">(</span><span class="n">trainPredict</span><span class="p">)</span><span class="o">+</span><span class="nb">len</span><span class="p">(</span><span class="n">valPredict</span><span class="p">)</span><span class="o">+</span><span class="p">(</span><span class="n">seq_size</span><span class="o">*</span><span class="mi">2</span><span class="p">),</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">valPredict</span>

    <span class="c1"># shift test predictions for plotting</span>
    <span class="n">testPredictPlot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">dataset</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">ext</span><span class="p">,</span> <span class="n">dataset</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">testPredictPlot</span><span class="p">[:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
    <span class="n">testPredictPlot</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">trainPredict</span><span class="p">)</span><span class="o">+</span><span class="nb">len</span><span class="p">(</span><span class="n">valPredict</span><span class="p">)</span><span class="o">+</span><span class="p">(</span><span class="n">seq_size</span><span class="o">*</span><span class="mi">3</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">:</span><span class="nb">len</span><span class="p">(</span><span class="n">trainPredict</span><span class="p">)</span><span class="o">+</span><span class="nb">len</span><span class="p">(</span><span class="n">valPredict</span><span class="p">)</span><span class="o">+</span><span class="nb">len</span><span class="p">(</span><span class="n">testPredict</span><span class="p">)</span><span class="o">+</span><span class="p">(</span><span class="n">seq_size</span><span class="o">*</span><span class="mi">3</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">testPredict</span>

    <span class="k">if</span> <span class="n">fcs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">fcPredictPlot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">dataset</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">ext</span><span class="p">,</span> <span class="n">dataset</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
      <span class="n">fcPredictPlot</span><span class="p">[:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
      <span class="n">fcPredictPlot</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">trainPredict</span><span class="p">)</span><span class="o">+</span><span class="nb">len</span><span class="p">(</span><span class="n">valPredict</span><span class="p">)</span><span class="o">+</span><span class="nb">len</span><span class="p">(</span><span class="n">testPredict</span><span class="p">)</span><span class="o">+</span><span class="p">(</span><span class="n">seq_size</span><span class="o">*</span><span class="mi">3</span><span class="p">)</span><span class="o">+</span><span class="mi">2</span><span class="p">:</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span><span class="o">+</span><span class="n">ext</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">fcs</span>

    <span class="c1"># plot baseline and predictions</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;dataset&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">trainPredictPlot</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">valPredictPlot</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;val&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">testPredictPlot</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;test&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">fcs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fcPredictPlot</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;m&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;forecasts&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;upper left&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Prediction&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Time&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Count&quot;</span><span class="p">)</span>
    <span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.dpi&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">200</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="k">return</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">scaler</span> <span class="o">=</span> <span class="n">read_data</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">seq_size</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1"># convert dataset into input/output</span>
<span class="n">trainX</span><span class="p">,</span> <span class="n">trainY</span> <span class="o">=</span> <span class="n">to_sequences</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">seq_size</span><span class="p">)</span>
<span class="n">valX</span><span class="p">,</span> <span class="n">valY</span> <span class="o">=</span> <span class="n">to_sequences</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">seq_size</span><span class="p">)</span>
<span class="n">testX</span><span class="p">,</span> <span class="n">testY</span> <span class="o">=</span> <span class="n">to_sequences</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="n">seq_size</span><span class="p">)</span>

<span class="n">train_features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">trainX</span><span class="p">)</span>
<span class="n">train_targets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">trainY</span><span class="p">)</span>

<span class="n">val_features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">valX</span><span class="p">)</span>
<span class="n">val_targets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">valY</span><span class="p">)</span>

<span class="n">test_features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">testX</span><span class="p">)</span>
<span class="n">test_targets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">testY</span><span class="p">)</span>

<span class="n">train</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">train_features</span><span class="p">,</span> <span class="n">train_targets</span><span class="p">)</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">val</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">val_features</span><span class="p">,</span> <span class="n">val_targets</span><span class="p">)</span>
<span class="n">val_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">test</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">test_features</span><span class="p">,</span> <span class="n">test_targets</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(500, 10, 3)
(209, 10, 3)
(354, 10, 3)
</pre></div>
</div>
</div>
</div>
<p>#Training here</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">seq_size</span>
<span class="n">output_dim</span> <span class="o">=</span> <span class="n">trainX</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">layer_dim</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">dropout</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">7e-5</span>
<span class="n">weight_decay</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">S4Layer</span><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="n">output_dim</span><span class="p">,</span> <span class="n">lmax</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">N</span><span class="o">=</span><span class="mi">1024</span><span class="p">)</span>

<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">)</span>

<span class="n">start</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>

<span class="n">opt</span> <span class="o">=</span> <span class="n">Optimization</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">)</span>
<span class="n">train_pred</span><span class="p">,</span> <span class="n">val_pred</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">n_epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="n">input_dim</span><span class="p">)</span>
<span class="n">opt</span><span class="o">.</span><span class="n">plot_losses</span><span class="p">()</span>

<span class="n">testPredict</span><span class="p">,</span> <span class="n">testValues</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_loader</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="n">input_dim</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[KeOps] Generating code for formula Sum_Reduction(ComplexMult(Real2Complex(1/ComplexSquareAbs(ComplexMult(Var(1,2,0)-Var(2,2,1),Var(1,2,0)-Conj(Var(2,2,1))))),ComplexMult(Var(1,2,0)*ComplexReal(Var(0,2,1))-Real2Complex(Sum(Var(0,2,1)*Var(2,2,1))),Conj(ComplexMult(Var(1,2,0)-Var(2,2,1),Var(1,2,0)-Conj(Var(2,2,1)))))),0) ... OK
[pyKeOps] Compiling pykeops cpp b2723628be module ... OK
[KeOps] Generating code for formula Sum_Reduction(ComplexAdd(ComplexAdd(ComplexAdd(Zero(2),Zero(2)),ComplexAdd(Zero(2),Zero(2))),ComplexAdd(Real2Complex(ComplexMult(Conj(Conj(ComplexMult(Var(1,2,0)-Var(2,2,1),Var(1,2,0)-Conj(Var(2,2,1))))),ComplexMult(Conj(Real2Complex(1/ComplexSquareAbs(ComplexMult(Var(1,2,0)-Var(2,2,1),Var(1,2,0)-Conj(Var(2,2,1)))))),Var(3,2,0)))|Var(1,2,0))-Var(2,2,1)*ComplexReal(ComplexMult(Conj(Conj(ComplexMult(Var(1,2,0)-Var(2,2,1),Var(1,2,0)-Conj(Var(2,2,1))))),ComplexMult(Conj(Real2Complex(1/ComplexSquareAbs(ComplexMult(Var(1,2,0)-Var(2,2,1),Var(1,2,0)-Conj(Var(2,2,1)))))),Var(3,2,0)))),ComplexAdd(Zero(2),Zero(2)))),1) ... OK
[pyKeOps] Compiling pykeops cpp 41d325d5a6 module ... OK
[1/1000] Training loss: 0.3975667176	 Validation loss: 0.3215299239
[2/1000] Training loss: 0.2452296960	 Validation loss: 0.1871205720
[3/1000] Training loss: 0.1621267263	 Validation loss: 0.1232012337
[4/1000] Training loss: 0.1139285904	 Validation loss: 0.0939432174
[5/1000] Training loss: 0.0860659560	 Validation loss: 0.0791227022
[6/1000] Training loss: 0.0680626665	 Validation loss: 0.0710599833
[7/1000] Training loss: 0.0598281783	 Validation loss: 0.0659343551
[8/1000] Training loss: 0.0546036973	 Validation loss: 0.0622480556
[9/1000] Training loss: 0.0498507800	 Validation loss: 0.0592484946
[10/1000] Training loss: 0.0489308910	 Validation loss: 0.0562070629
[11/1000] Training loss: 0.0445171027	 Validation loss: 0.0532531030
[12/1000] Training loss: 0.0451617468	 Validation loss: 0.0506770684
[13/1000] Training loss: 0.0393992212	 Validation loss: 0.0484790338
[14/1000] Training loss: 0.0408640971	 Validation loss: 0.0462960311
[15/1000] Training loss: 0.0347678474	 Validation loss: 0.0442034728
[16/1000] Training loss: 0.0345138710	 Validation loss: 0.0424583654
[17/1000] Training loss: 0.0349718800	 Validation loss: 0.0411393907
[18/1000] Training loss: 0.0316869317	 Validation loss: 0.0398467283
[19/1000] Training loss: 0.0308607592	 Validation loss: 0.0384677506
[20/1000] Training loss: 0.0320821494	 Validation loss: 0.0373359658
[21/1000] Training loss: 0.0301829349	 Validation loss: 0.0364224120
[22/1000] Training loss: 0.0300843807	 Validation loss: 0.0352663268
[23/1000] Training loss: 0.0288799238	 Validation loss: 0.0345396213
[24/1000] Training loss: 0.0280774171	 Validation loss: 0.0336398156
[25/1000] Training loss: 0.0268130951	 Validation loss: 0.0329119664
[26/1000] Training loss: 0.0267249145	 Validation loss: 0.0322399620
[27/1000] Training loss: 0.0262008632	 Validation loss: 0.0316460352
[28/1000] Training loss: 0.0262986336	 Validation loss: 0.0310588816
[29/1000] Training loss: 0.0244766315	 Validation loss: 0.0305468866
[30/1000] Training loss: 0.0250093794	 Validation loss: 0.0301474862
[31/1000] Training loss: 0.0246955228	 Validation loss: 0.0297624614
[32/1000] Training loss: 0.0244794949	 Validation loss: 0.0292858329
[33/1000] Training loss: 0.0239425514	 Validation loss: 0.0288950047
[34/1000] Training loss: 0.0232428359	 Validation loss: 0.0285726080
[35/1000] Training loss: 0.0228380964	 Validation loss: 0.0281853306
[36/1000] Training loss: 0.0228417431	 Validation loss: 0.0279169523
[37/1000] Training loss: 0.0226011828	 Validation loss: 0.0276834662
[38/1000] Training loss: 0.0228656342	 Validation loss: 0.0274214904
[39/1000] Training loss: 0.0222149668	 Validation loss: 0.0272522353
[40/1000] Training loss: 0.0227482604	 Validation loss: 0.0271272084
[41/1000] Training loss: 0.0220415004	 Validation loss: 0.0268759498
[42/1000] Training loss: 0.0219147906	 Validation loss: 0.0268789593
EarlyStopping counter: 1 out of 20
[43/1000] Training loss: 0.0218512668	 Validation loss: 0.0267143149
[44/1000] Training loss: 0.0217353740	 Validation loss: 0.0264571457
[45/1000] Training loss: 0.0223497381	 Validation loss: 0.0264029961
[46/1000] Training loss: 0.0212915528	 Validation loss: 0.0262588585
[47/1000] Training loss: 0.0210976398	 Validation loss: 0.0261766171
[48/1000] Training loss: 0.0208362799	 Validation loss: 0.0259988220
[49/1000] Training loss: 0.0212390035	 Validation loss: 0.0259231313
[50/1000] Training loss: 0.0210828057	 Validation loss: 0.0258675955
[51/1000] Training loss: 0.0207703903	 Validation loss: 0.0258197313
[52/1000] Training loss: 0.0213090660	 Validation loss: 0.0257773601
[53/1000] Training loss: 0.0215673038	 Validation loss: 0.0256946675
[54/1000] Training loss: 0.0207254220	 Validation loss: 0.0256196097
[55/1000] Training loss: 0.0203186031	 Validation loss: 0.0255428839
[56/1000] Training loss: 0.0208514443	 Validation loss: 0.0255156088
[57/1000] Training loss: 0.0205829427	 Validation loss: 0.0254372306
[58/1000] Training loss: 0.0201137920	 Validation loss: 0.0254077865
[59/1000] Training loss: 0.0198724198	 Validation loss: 0.0253836003
[60/1000] Training loss: 0.0200607457	 Validation loss: 0.0252729052
[61/1000] Training loss: 0.0195864688	 Validation loss: 0.0251927951
[62/1000] Training loss: 0.0195380268	 Validation loss: 0.0251191283
[63/1000] Training loss: 0.0195270078	 Validation loss: 0.0251036160
[64/1000] Training loss: 0.0191872980	 Validation loss: 0.0251004878
[65/1000] Training loss: 0.0199011207	 Validation loss: 0.0250675490
[66/1000] Training loss: 0.0186858885	 Validation loss: 0.0250653076
[67/1000] Training loss: 0.0187136018	 Validation loss: 0.0250130083
[68/1000] Training loss: 0.0192897423	 Validation loss: 0.0250256884
EarlyStopping counter: 1 out of 20
[69/1000] Training loss: 0.0185365226	 Validation loss: 0.0250316276
EarlyStopping counter: 2 out of 20
[70/1000] Training loss: 0.0189704289	 Validation loss: 0.0251277869
EarlyStopping counter: 3 out of 20
[71/1000] Training loss: 0.0186915814	 Validation loss: 0.0251914097
EarlyStopping counter: 4 out of 20
[72/1000] Training loss: 0.0186409826	 Validation loss: 0.0252391788
EarlyStopping counter: 5 out of 20
[73/1000] Training loss: 0.0184280647	 Validation loss: 0.0252191421
EarlyStopping counter: 6 out of 20
[74/1000] Training loss: 0.0183907217	 Validation loss: 0.0252824768
EarlyStopping counter: 7 out of 20
[75/1000] Training loss: 0.0182061967	 Validation loss: 0.0254028175
EarlyStopping counter: 8 out of 20
[76/1000] Training loss: 0.0189231586	 Validation loss: 0.0255348081
EarlyStopping counter: 9 out of 20
[77/1000] Training loss: 0.0175437861	 Validation loss: 0.0256469298
EarlyStopping counter: 10 out of 20
[78/1000] Training loss: 0.0183079105	 Validation loss: 0.0258122979
EarlyStopping counter: 11 out of 20
[79/1000] Training loss: 0.0177624392	 Validation loss: 0.0256580046
EarlyStopping counter: 12 out of 20
[80/1000] Training loss: 0.0177786801	 Validation loss: 0.0257502605
EarlyStopping counter: 13 out of 20
[81/1000] Training loss: 0.0173806902	 Validation loss: 0.0255141923
EarlyStopping counter: 14 out of 20
[82/1000] Training loss: 0.0181775513	 Validation loss: 0.0255261922
EarlyStopping counter: 15 out of 20
[83/1000] Training loss: 0.0172553053	 Validation loss: 0.0255042233
EarlyStopping counter: 16 out of 20
[84/1000] Training loss: 0.0179880402	 Validation loss: 0.0254615030
EarlyStopping counter: 17 out of 20
[85/1000] Training loss: 0.0170253328	 Validation loss: 0.0252983308
EarlyStopping counter: 18 out of 20
[86/1000] Training loss: 0.0171340041	 Validation loss: 0.0253197564
EarlyStopping counter: 19 out of 20
[87/1000] Training loss: 0.0169874294	 Validation loss: 0.0251753815
EarlyStopping counter: 20 out of 20
We are at epoch: 87
</pre></div>
</div>
<img alt="../_images/28b769ab124184e37ad020a0f69c2305f70bb01dff56ff100bd20a590ecbbe27.png" src="../_images/28b769ab124184e37ad020a0f69c2305f70bb01dff56ff100bd20a590ecbbe27.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># df_dataset = scaler.inverse_transform(dataset)</span>
<span class="n">df_train</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">train_pred</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">df_val</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">val_pred</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">df_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">testPredict</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">plotting</span> <span class="p">(</span><span class="n">dataset</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">df_train</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">df_val</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">df_test</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="c1">#plotting without inverse_transform</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/0736519ce40b60ca422758f385515cf5d7df0293be63d78509b0ed2487a66eca.png" src="../_images/0736519ce40b60ca422758f385515cf5d7df0293be63d78509b0ed2487a66eca.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">plotting</span> <span class="p">(</span><span class="n">dataset</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">df_train</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">df_val</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">df_test</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="c1">#plotting without inverse_transform</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/b97e648f5a3f9fc860aa7c618d78b852f00f4b95d74da89cee2ad4694e0d6be1.png" src="../_images/b97e648f5a3f9fc860aa7c618d78b852f00f4b95d74da89cee2ad4694e0d6be1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">df_test</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">scaler</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">testY</span><span class="p">)[:,</span> <span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1013.0438425712225
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">df_test</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">scaler</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">testY</span><span class="p">)[:,</span> <span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>25.823480377448703
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">mape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
  <span class="n">error</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">/</span><span class="nb">abs</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
  <span class="n">error</span><span class="p">[</span><span class="n">error</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
  <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>

<span class="n">mape</span><span class="p">(</span><span class="n">df_test</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">scaler</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">testY</span><span class="p">)[:,</span> <span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.7516595798745832
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">df_test</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">scaler</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">testY</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1741656924.3608289
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">df_test</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">scaler</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">testY</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>34469.24461511299
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">mape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
  <span class="n">error</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">/</span><span class="nb">abs</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
  <span class="n">error</span><span class="p">[</span><span class="n">error</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
  <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>

<span class="n">mape</span><span class="p">(</span><span class="n">df_test</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">scaler</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">testY</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.09769348272151332
</pre></div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./Models"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="simple visible nav section-nav flex-column">
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            <div class="bd-footer-content__inner">
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Nghia Le, Lance Zheng
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div></div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=12da95d707ffb74b382d"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=12da95d707ffb74b382d"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>